{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQYHn_ZA43WQ"
      },
      "source": [
        "# House Price Prediction\n",
        "\n",
        "Let's look at supervised learning in a classic ML course example: predicting house prices.\n",
        "\n",
        "Our goal is going to build a prediction model to predict the sale price of a house based on easily observed features. The data are from the Seattle, WA area for a few months in 2014.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVwPwD_75j3o"
      },
      "source": [
        "We start by importing packages we will be using. See [our first example](https://colab.research.google.com/github/chansen776/MBA-ML-Course-Materials/blob/main/Code/BiasVarianceExample1.ipynb).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CUO7PPC342qq",
        "outputId": "6c0c7098-5a1a-4730-8396-6d1f51b4e40a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting formulaic\n",
            "  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting interface-meta>=1.2.0 (from formulaic)\n",
            "  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.11/dist-packages (from formulaic) (2.0.2)\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic) (2.2.2)\n",
            "Requirement already satisfied: scipy>=1.6 in /usr/local/lib/python3.11/dist-packages (from formulaic) (1.14.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic) (4.13.1)\n",
            "Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic) (1.17.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->formulaic) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->formulaic) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0->formulaic) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0->formulaic) (1.17.0)\n",
            "Downloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: interface-meta, formulaic\n",
            "Successfully installed formulaic-1.1.1 interface-meta-1.3.0\n"
          ]
        }
      ],
      "source": [
        "# Install extra libraries\n",
        "!pip install formulaic\n",
        "from formulaic import model_matrix\n",
        "\n",
        "# Import relevant packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.model_selection import KFold, GridSearchCV\n",
        "from sklearn.model_selection import cross_validate, cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import QuantileRegressor\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.tree import plot_tree\n",
        "\n",
        "# Not the best practice, but we're going to suppress warnings for ease of display\n",
        "# if we're looking at things during teaching\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Seed we will use for random number generators\n",
        "rng = 713\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGTjeNS_5r_P"
      },
      "source": [
        "# Load and examine the data\n",
        "\n",
        "We need to load the data. We will do this directly from a github repository for the course."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZ7XYfNl5wIY"
      },
      "outputs": [],
      "source": [
        "file = \"https://raw.githubusercontent.com/chansen776/MBA-ML-Course-Materials/main/Data/WAHousePrice.xlsx\"\n",
        "data = pd.read_excel(file)\n",
        "data.shape  # See size of dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uawq8W9i6NF-"
      },
      "source": [
        "Let's take a look at what's in the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOd_qOmg6Nwz"
      },
      "outputs": [],
      "source": [
        "data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NNBQ2oc66VdH"
      },
      "outputs": [],
      "source": [
        "data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATh6tWpfX7lY"
      },
      "source": [
        "The maximum price 2.659000e+07 = 26,590,000 seems very high. We'll look at this again in a second. There are also some very low prices and properties with 0 bedrooms and bathrooms. Nothing else in the summary statistics stands out as particularly noteworthy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20EfbUuMfhJM"
      },
      "source": [
        "Do the the square footage variables `sqft_living`, `sqft_above` and `sqft_basement` capture different information?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oUZ3VAEsfqI_"
      },
      "outputs": [],
      "source": [
        "# Let's calculate the correlation of sqft_living with sqft_above+sqft_basement\n",
        "print('Correlation of sqft_living with (sqft_above+sqft_basement):',\n",
        "      data['sqft_living'].corr(data['sqft_above']+data['sqft_basement']))\n",
        "\n",
        "# Let's calculate the correlation with each element instead\n",
        "print('Correlation of sqft_living with sqft_above:',\n",
        "      data['sqft_living'].corr(data['sqft_above']))\n",
        "print('Correlation of sqft_living with sqft_basement:',\n",
        "      data['sqft_living'].corr(data['sqft_basement']))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxD3-Zz5hdca"
      },
      "source": [
        "Cannot use `sqft_living` and both `sqft_basement` and `sqft_above` in the same linear model estimated by least squares (or least absolute values).\n",
        "\n",
        "**Question:** How do we choose which to use?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DfMcCMY1SFR-"
      },
      "source": [
        "Let's quickly examine the 0 bedroom and 0 bathroom observations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KKexVSP_Ss25"
      },
      "outputs": [],
      "source": [
        "# Let's find the observations with 0 bedrooms or 0 bathrooms and see what they look like\n",
        "data[(data['bedrooms'] == 0) | (data['bathrooms'] == 0)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5QrRPhGTTb7"
      },
      "source": [
        "I'm pretty confident that houses with 3000+ square feet of living space should have bathrooms and bedrooms. We could try to *impute* what seem to be the missing values of bathrooms and bedrooms for these two observations. Because it's only two observations, I'm just going to delete them instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwOtqUt9UBRw"
      },
      "outputs": [],
      "source": [
        "# Drop the flagged observations\n",
        "data = data.drop(data[(data['bedrooms'] == 0) | (data['bathrooms'] == 0)].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tO6mB_Do6mku"
      },
      "outputs": [],
      "source": [
        "data.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVRInON3N63g"
      },
      "source": [
        "Some of the variables `street`, `city`, `statezip`, and `country` are not numeric, so don't show up in the summary table. We'll look at these variables after examining the outcome in a bit more detail."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw4BOYN3DS25"
      },
      "source": [
        "**Outcome variable**\n",
        "\n",
        "Let's start by seeing what the outcome variable looks like."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdPkwUZbDvZi"
      },
      "outputs": [],
      "source": [
        "# Smoothed histogram of the outcome variable, price\n",
        "sns.displot(data=data, x='price', kind='kde')\n",
        "plt.title('Smoothed histogram of Price')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yog_xRoeYVAK"
      },
      "outputs": [],
      "source": [
        "plt.scatter(data['sqft_living'], data['price'])\n",
        "plt.xlabel('sqft_living')\n",
        "plt.ylabel('price')\n",
        "plt.title('Scatter plot of Price vs Square Feet')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwjd2j9rYlmQ"
      },
      "source": [
        "There are two observations that are probably worth another look. Also recall that there was at least one very low price from the summary statistics. Let's look at both."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zb4dHNQsSLeL"
      },
      "outputs": [],
      "source": [
        "# Let's find the observations with very low prices and see what they look like\n",
        "data[data['price'] < 50000]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEPgRHDNSaw7"
      },
      "source": [
        "It seems a bit out of the realm of possibility to have a $7800 dollar property in the Seattle area in 2014, though the property seems not particularly desirable. I'm going to assume that the price here is incorrect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lj546lWFYqW4"
      },
      "outputs": [],
      "source": [
        "# Let's find the observations with very high prices and see what they look like\n",
        "data[data['price'] > 5000000]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pU877AU7ZPUs"
      },
      "source": [
        "I can believe that a 10000 square foot property sold for \\$7M.\n",
        "\n",
        "I have a hard time believing a 2 bathroom, 3 bedroom, 1180 square foot property sold for ~\\$27M. This seems like a mistake. I'm also having a hard time believing that a 2.5 bathroom, 3 bedroom, 2190 square foot property sold for ~\\$13M.\n",
        "\n",
        "I am going to treat both of these observations as \"mistakes\" and drop them from my data. I am going to recognize that if these are real observations, there is a small chance I will see future properties that I make GIGANTIC mistakes on.\n",
        "\n",
        "We can/should also run the whole thing with the dropped observations included to gauge robustness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyHGl2UKazJs"
      },
      "outputs": [],
      "source": [
        "# Drop the flagged observations\n",
        "data = data.drop(data[data['price'] < 50000].index)\n",
        "data = data.drop(data[data['price'] > 10000000].index)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9gHuBoOEOPS"
      },
      "source": [
        "Our price variable is highly skewed. It is very commeon to see data-scientists build models a right-skewed variable that only takes on positive values by taking a `log` transformation first. I.e. instead by building a model for `price`, we might instead build a model for `log(price)`.\n",
        "\n",
        "**Remember that our goal is to predict `price` though!** Make sure you validate on the basis of what you care about."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T9kQ7vusENjZ"
      },
      "outputs": [],
      "source": [
        "# Create new column with the log of price\n",
        "data['log_price'] = np.log(data['price'])\n",
        "\n",
        "# Smoothed histogram of log price\n",
        "sns.displot(data=data, x='log_price', kind='kde')\n",
        "plt.title('Smoothed histogram of log(Price)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01Z8MJOSUicp"
      },
      "outputs": [],
      "source": [
        "plt.scatter(data['sqft_living'], data['log_price'])\n",
        "plt.xlabel('sqft_living')\n",
        "plt.ylabel('log_price')\n",
        "plt.title('Scatter plot of log(Price) vs Square Feet')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What happens if we look at log(`sqft_living`)?"
      ],
      "metadata": {
        "id": "lfA3IKZrFi4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(np.log(data['sqft_living']), data['log_price'])\n",
        "plt.xlabel('log_sqft_living')\n",
        "plt.ylabel('log_price')\n",
        "plt.title('Scatter plot of log(Price) vs log(Square Feet)')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eLeR3Z9yFifL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That actually looks pretty reasonable. Let's consider using the log of all our square footage variables."
      ],
      "metadata": {
        "id": "oTpk5_U-FpRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace square footage variables with their log\n",
        "data['sqft_living'] = np.log(data['sqft_living'])\n",
        "data['sqft_lot'] = np.log(data['sqft_lot'])\n",
        "data['sqft_above'] = np.log(data['sqft_above'])"
      ],
      "metadata": {
        "id": "QwG5mLHHFv0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sqft_basement has 0 values that indicate no basement. We don't want to replace those\n",
        "data.loc[data[\"sqft_basement\"] > 0, \"sqft_basement\"] = np.log(data.loc[data[\"sqft_basement\"] > 0, \"sqft_basement\"])"
      ],
      "metadata": {
        "id": "BGnsDDAwFxgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nhLnWdnC15E"
      },
      "source": [
        "**Categorical Variables**\n",
        "\n",
        "The four variables of type \"object\" are not numeric but coded as text. Let's look at what they are. In the following code blocks, we are just going to tabulate each of our categorical variables by looking at the `value_counts` property of our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIHslh748P1P"
      },
      "outputs": [],
      "source": [
        "data['street'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA8BYDoC8Z2F"
      },
      "source": [
        "Most street addresses have only one property. Without better geographic knowledge, it's going to be hard to use this variable.\n",
        "\n",
        "**Question:** If you really cared, how could you use the street address to get something potentially more useful? (Think about, e.g., google street view, google maps and routing, ...)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HCTrdnLG7RN8"
      },
      "outputs": [],
      "source": [
        "data['city'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.sum(data['city'].value_counts() < 20)"
      ],
      "metadata": {
        "id": "veZPcomuLmX_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wc0vXdpQ9GP7"
      },
      "source": [
        "City might be useful, but it is very unbalanced.\n",
        "\n",
        "**Questions:**\n",
        "\n",
        "1. Do we think the actual name of the city matters? Why might the variable `city` contain useful information?\n",
        "\n",
        "2. If we want to predict something outside of the Seattle area, is the variable `city` useful? Could we make it useful with some more effort?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrDAoWmE73aQ"
      },
      "outputs": [],
      "source": [
        "data['statezip'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBSDYNmx9Peg"
      },
      "source": [
        "Zip code (`statezip`) seems like it might have more *interesting* variation than `city`.\n",
        "\n",
        "**Questions:**\n",
        "\n",
        "1. Do we think the actual numeric value of a property's zip code matters? Why might the variable `statezip` contain useful information?\n",
        "\n",
        "2. If we want to predict something outside of the Seattle area, is the variable `statezip` useful? Could we make it useful with some more effort?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9DgmDtJ8DeX"
      },
      "outputs": [],
      "source": [
        "data['country'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BWgtK6z8JZE"
      },
      "source": [
        "Can't use the variable `country` - It doesn't *vary* üôÇ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzakdBbUb0ax"
      },
      "source": [
        "**Aside: Categorical Variables.**\n",
        "\n",
        "The typical way to use (unordered) categorical variables is to encode them as dummy variables/binary variables/use one-hot-encoding --  all of which are jargon for making a new set of variables that are 0 or 1 with 1 indicating the observation belongs to a category and 0 indicates it does not.\n",
        "\n",
        "For example, if we had a variable `color` with two categories \"red\" and \"blue\", we just create two new variables `red` and `blue` where variable `red` = 1 for all observations that are red (and 0 otherwise) and `blue` is defined similarly. (Note: For standard linear models, you typically exclude one of the dummy variables. In our toy example, we don't need both the variables `red` and `blue` because if `red` = 1 we know `blue` = 0 and viceversa. That is, they have the same information.)\n",
        "\n",
        "We'll look at doing this in our price example when we consider including `city` and `statezip` in our model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKBUm9pS_a--"
      },
      "source": [
        "Before doing anything else, let's drop the variables we definitely won't use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khWiCZII_e84"
      },
      "outputs": [],
      "source": [
        "data = data.drop(columns=['date','street','country'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBggP2xO_6cA"
      },
      "source": [
        "Finally, we also see that we have many other variables that are effectively capturing qualitative information or a mix. E.g. `bathrooms`, `bedrooms`, `floors`, `waterfront`, `view`, and `condition` might be thought of as categorical.\n",
        "\n",
        "Let's look at these variables more carefully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FxcmTUmJBsKw"
      },
      "outputs": [],
      "source": [
        "print(data['bathrooms'].value_counts())\n",
        "print('\\n')\n",
        "print(data['bedrooms'].value_counts())\n",
        "print('\\n')\n",
        "print(data['floors'].value_counts())\n",
        "print('\\n')\n",
        "print(data['waterfront'].value_counts())\n",
        "print('\\n')\n",
        "print(data['view'].value_counts())\n",
        "print('\\n')\n",
        "print(data['condition'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAJI0_7yy0Rq"
      },
      "source": [
        "Importantly, these variables all have an order to them. `bathrooms`, `bedrooms`, and `floors` also (arguably) have cardinal value. `view` and `condition` are clearly qualitative, but do have ordinal meaning. `waterfront` is already a dummy variable.\n",
        "\n",
        "We could treat these by including them as dummy variables, but it also makes sense to use them as is (which is what we are going to do). Many ML procedures will happily and appropriately deal with ordered categorical features and numeric features with few values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNO8PYJXvmj4"
      },
      "source": [
        "**Mixed variables**\n",
        "\n",
        "The variables `sqft_basement` and `yr_renovated` have a 0 category indicating \"no basement\" or \"never renovated\" respectively.\n",
        "\n",
        "We can add variables indicating the qualitative information. For many learners, adding this variable is also unnecessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqEo4UkTvssh"
      },
      "outputs": [],
      "source": [
        "# Add a variable for being renovated\n",
        "data['renovated_flag'] = np.where(data['yr_renovated'] == 0, 0, 1)\n",
        "\n",
        "# Add a variable for having a basement\n",
        "data['basement_flag'] = np.where(data['sqft_basement'] == 0, 0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO-cm2jqWdH5"
      },
      "source": [
        "# Model evaluation\n",
        "\n",
        "We are going to use 5-fold CV to evaluate our models. We want to keep the cross-validation folds the same across all of the models we build, so we're going to predefine the splits."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCFKawjSMkvH"
      },
      "outputs": [],
      "source": [
        "cvsplit = KFold(n_splits=5, shuffle=True, random_state=rng)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-NHEZ36W5SB"
      },
      "source": [
        "We also need to choose how to evaluate the models. For illustration, we're going to consider performance based on both MAE and MSE. We are going to estimate models using both `price` and `log_price` for illustration.\n",
        "\n",
        "When we build a model for `log_price`, we don't directly build a prediction rule for `price`. We are going to use the simplest approach to turning our `log_price` prediction into a `price` prediction by exponentiating. I.e. if $\\widehat{\\texttt{log_price}}$ is our prediction for `log_price`, we obtain a prediction for `price` as $\\exp\\{\\widehat{\\texttt{log_price}}\\}$.\n",
        "\n",
        "We're going to define functions to produce MSE and MAE from `log_price` predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Htclo5CJNsXx"
      },
      "outputs": [],
      "source": [
        "def expmse(y_true, y_pred):\n",
        "\n",
        "  y_true = y_true.to_numpy()\n",
        "  y_pred[y_pred < -20] = -20\n",
        "  y_pred[y_pred > 20] = 20 # Prevent overflow issues in really bad models because we are going to exponentiate\n",
        "  negmse = -np.mean((np.exp(y_true) - np.exp(y_pred))**2)\n",
        "\n",
        "  return negmse\n",
        "\n",
        "# Create a scorer object using the expmse function\n",
        "expmse_score = make_scorer(expmse)\n",
        "\n",
        "def expmae(y_true, y_pred):\n",
        "\n",
        "  y_true = y_true.to_numpy()\n",
        "  y_pred[y_pred < -20] = -20\n",
        "  y_pred[y_pred > 20] = 20 # Prevent overflow issues in really bad models because we are going to exponentiate\n",
        "  negmae = -np.mean(np.abs(np.exp(y_true) - np.exp(y_pred)))\n",
        "\n",
        "  return negmae\n",
        "\n",
        "# Create a scorer object using the expmae function\n",
        "expmae_score = make_scorer(expmae)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "thTV0AIN_Wop"
      },
      "source": [
        "# Baseline start\n",
        "\n",
        "As simple benchmark, let's look at sample means and medians.\n",
        "\n",
        "We're going to define functions for using the mean and median as prediction rules that we can use with `sklearn`'s built in cross-validation functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DF3ZbJg8Pq8d"
      },
      "outputs": [],
      "source": [
        "# Define function to use mean as estimator and make prediction\n",
        "class MeanEstimator(BaseEstimator, RegressorMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        # Compute the mean of y during fitting\n",
        "        self.mean_ = np.mean(y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Return the mean for all predictions\n",
        "        return np.full(len(X), self.mean_)\n",
        "\n",
        "# Define function to use median as estimator and make prediction\n",
        "class MedianEstimator(BaseEstimator, RegressorMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        # Compute the mean of y during fitting\n",
        "        self.median_ = np.median(y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        # Return the mean for all predictions\n",
        "        return np.full(len(X), self.median_)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRvHRko8YKNX"
      },
      "source": [
        "Let's look at how well the sample mean and sample median of `price` do for predicting `price` by 5-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y78A3ulaUXhB"
      },
      "outputs": [],
      "source": [
        "# Cross validation RMSE and MAE using sample mean of price as prediction rule\n",
        "# The \"scoring\" argument tells cross-validation what out-of-sample prediction\n",
        "# metrics to compute.\n",
        "levmean_mse = cross_validate(MeanEstimator(), data['price'], data['price'],\n",
        "                             scoring=('neg_mean_squared_error','neg_mean_absolute_error'), cv=cvsplit)\n",
        "print('Level Mean: CV RMSE: {m1:=.2f}; CV MAE: {m2:=.2f}'\n",
        "  .format(m1=np.sqrt(-levmean_mse['test_neg_mean_squared_error'].mean()),\n",
        "          m2=-levmean_mse['test_neg_mean_absolute_error'].mean()))\n",
        "\n",
        "# Cross validation RMSE and MAE using sample median of price as prediction rule\n",
        "# The \"scoring\" argument tells cross-validation what out-of-sample prediction\n",
        "# metrics to compute.\n",
        "levmedian_mse = cross_validate(MedianEstimator(), data['price'], data['price'],\n",
        "                               scoring=('neg_mean_squared_error','neg_mean_absolute_error'), cv=cvsplit)\n",
        "print('Level Median: CV RMSE: {m1:=.2f}; CV MAE: {m2:=.2f}'\n",
        "  .format(m1=np.sqrt(-levmedian_mse['test_neg_mean_squared_error'].mean()),\n",
        "          m2=-levmedian_mse['test_neg_mean_absolute_error'].mean()))\n",
        "\n",
        "# We are going to use cross-validated MSE from the mean as our benchmark for MSE\n",
        "# We are going to use cross-validated MAE from the median as our benchmark for MAE\n",
        "benchMSE = -levmean_mse['test_neg_mean_squared_error'].mean()\n",
        "benchMAE = -levmedian_mse['test_neg_mean_absolute_error'].mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cyy4YO2jFtB5"
      },
      "outputs": [],
      "source": [
        "# Let's create a table to keep track of results\n",
        "model_results = pd.DataFrame()\n",
        "model_results['Model'] = ['Mean', 'Median']\n",
        "model_results['RMSE'] = [np.sqrt(-levmean_mse['test_neg_mean_squared_error'].mean()),\n",
        "                         np.sqrt(-levmedian_mse['test_neg_mean_squared_error'].mean())]\n",
        "model_results['R2 - MSE'] = [None,None]\n",
        "model_results['MAE'] = [-levmean_mse['test_neg_mean_absolute_error'].mean(),\n",
        "                        -levmedian_mse['test_neg_mean_absolute_error'].mean()]\n",
        "model_results['R2 - MAE'] = [None,None]\n",
        "model_results['p'] = [None,None]\n",
        "model_results['p_use'] = [None,None]\n",
        "model_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwJfKKof0ZGS"
      },
      "source": [
        "# Baseline linear models.\n",
        "\n",
        "## Think about the model\n",
        "\n",
        "For black box machine learners that discover nonlinearity automatically, thinking about how to model nonlinearity and other transformations to make of our available variables is not a big issue. The ability to put less time into  thinking about these issues is a major plus for ML algorithms. **You should always be thoughtful about variables in a model though.**\n",
        "\n",
        "For learners like linear regression, thinking about the appropriate way to include variables is potentially very important though.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_muYOXDf4eMR"
      },
      "source": [
        "## Baseline models: OLS"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our baseline models, we are going to repeatedly apply the same steps. Let's write some functions so we don't have to keep typing the same things."
      ],
      "metadata": {
        "id": "pJEoxSgCdUb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_cross_validation(model, X, y, scoring, cvsplit, benchMSE, benchMAE, p):\n",
        "\n",
        "    results = cross_validate(model, X, y, scoring=scoring, cv=cvsplit)\n",
        "\n",
        "    rmse = np.sqrt(-results['test_mse'].mean())\n",
        "    r2 = 1 - (-results['test_mse'].mean() / benchMSE)\n",
        "    mae = -results['test_mae'].mean()\n",
        "    mae_r2 = 1 - (-results['test_mae'].mean() / benchMAE)\n",
        "    print(f'CV RMSE: {rmse:.2f}; CV R2: {r2:.3f}; p: {p:.0f}')\n",
        "    print(f'CV MAE: {mae:.2f}; CV MAE R2: {mae_r2:.3f}; p: {p:.0f}')\n",
        "\n",
        "    return results\n",
        "\n",
        "def update_model_results(model_results, model_name, results, p, p_use):\n",
        "\n",
        "    rmse = np.sqrt(-results['test_mse'].mean())\n",
        "    r2 = 1 - (-results['test_mse'].mean() / benchMSE)\n",
        "    mae = -results['test_mae'].mean()\n",
        "    mae_r2 = 1 - (-results['test_mae'].mean() / benchMAE)\n",
        "    model_results = model_results._append({\n",
        "        'Model': model_name,\n",
        "        'RMSE': rmse,\n",
        "        'R2 - MSE': r2,\n",
        "        'MAE': mae,\n",
        "        'R2 - MAE': mae_r2,\n",
        "        'p': p,\n",
        "        'p_use': p_use }, ignore_index=True)\n",
        "\n",
        "    return model_results\n"
      ],
      "metadata": {
        "id": "FkePNswXddBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to keep track of MSE and MAE for price. Let's define the metrics we're looking at."
      ],
      "metadata": {
        "id": "P_74w47zf99Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation metrics\n",
        "scoring_lev = {'mse': 'neg_mean_squared_error',\n",
        "               'mae': 'neg_mean_absolute_error'}\n",
        "\n",
        "scoring_log = {'mse': expmse_score,\n",
        "               'mae': expmae_score}"
      ],
      "metadata": {
        "id": "Xq8hqfP_gFNt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to use the \"formula\" interfact we imported from formulaic to help define our models.\n",
        "\n",
        "The basics we will use:\n",
        "1. Putting a variable inside \"C\" will make the variable be treated as categorical by turning it into dummy variables.\n",
        "2. Putting a variable inside \"poly\" will create a polynomial of \"degree\" in that variable\n",
        "3. Putting a : between variables creates the interaction between those variables\n",
        "4. Putting a * between variables includes the variables and their interactions\n"
      ],
      "metadata": {
        "id": "6cOu87jIgZCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Linear terms in all baseline variables\n",
        "pure = (\"price ~ bathrooms + bedrooms + sqft_living + sqft_lot + floors \"\n",
        "            \"+ waterfront + view + condition + yr_built + yr_renovated + renovated_flag + basement_flag\")\n",
        "\n",
        "# Create variables based on model defined in formula\n",
        "y, X = model_matrix(pure, data)\n",
        "n, p_pure = X.shape\n",
        "\n",
        "# Outcome variable for log models\n",
        "logy = data['log_price']"
      ],
      "metadata": {
        "id": "LgQrciN1YW7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're now going to estimate and evaluate our baseline model for `price` and for `log_price` using the five fold cross-validation splits defined [above](https://colab.research.google.com/github/chansen776/MBA-ML-Course-Materials/blob/main/Code/HousePriceExample1.ipynb#scrollTo=FCFKawjSMkvH&line=1&uniqifier=1).\n",
        "\n"
      ],
      "metadata": {
        "id": "Vho4md-9hR2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic regression for price\n",
        "purelm = perform_cross_validation(LinearRegression(), X, y,\n",
        "                                  scoring=scoring_lev,\n",
        "                                  cvsplit=cvsplit,\n",
        "                                  benchMSE=benchMSE,\n",
        "                                  benchMAE=benchMAE,\n",
        "                                  p=p_pure)\n",
        "model_results = update_model_results(model_results, 'LM', purelm, p_pure, p_pure)\n",
        "\n",
        "# Basic regression for log-price\n",
        "pureloglm = perform_cross_validation(LinearRegression(), X, logy,\n",
        "                                  scoring=scoring_log,\n",
        "                                  cvsplit=cvsplit,\n",
        "                                  benchMSE=benchMSE,\n",
        "                                  benchMAE=benchMAE,\n",
        "                                  p=p_pure)\n",
        "model_results = update_model_results(model_results, 'logLM', pureloglm, p_pure, p_pure)"
      ],
      "metadata": {
        "id": "byaTrJ-1Yuh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NUsv_1Bugfz"
      },
      "source": [
        "**Nonlinearity**\n",
        "\n",
        "We should think about potential *nonlinearities* that we would like to allow our models to capture. For example, do we think that each unit increase in house's square footage at fixed values of other variables should be associated with the same change in predicted (log) price regardless of the square footage? E.g. do we think going from 1000 to 1100 square feet is the same \"value\" as going from 3000-3100 square feet? Do we think the \"value\" of going from 2000-2100 square feet is the same if we are talking about a three versus five bedroom property?\n",
        "\n",
        "A very simple and interpretable way to allow for nonlinearities is to use *polynomials* and *interactions*. E.g. we might include `sqft_living` and `sqft_living`$^2$ to allow for decreasing or increasing \"returns\" to square footage in our model, so our prediction rule would be\n",
        "\n",
        "$$\\widehat{\\texttt{price}} = b_0 + b_1 \\texttt{sqft_living} + b_2 \\texttt{sqft_living}^2 + ...$$\n",
        "\n",
        "or\n",
        "\n",
        "$$\\widehat{\\texttt{log_price}} = b_0 + b_1 \\texttt{sqft_living} + b_2 \\texttt{sqft_living}^2 + ...$$\n",
        "\n",
        "[Note that you cannot interpret $b_1$ and $b_2$ in isolation.]\n",
        "\n",
        "We might also include the *interaction* `sqft_living`*`bedrooms` to allow the predicted price change for a given change in `sqft_living` to be different for properties with different numbers of bedrooms. In this case, our model would be\n",
        "\n",
        "$$ \\widehat{\\texttt{price}} = b_0 + b_1 \\texttt{sqft_living} + b_2 \\texttt{sqft_living}^2 + b_3\\texttt{bedrooms} + b_4 \\texttt{sqft_living}*\\texttt{bedrooms} + ...$$\n",
        "\n",
        "or\n",
        "\n",
        "$$ \\widehat{\\texttt{log_price}} = b_0 + b_1 \\texttt{sqft_living} + b_2 \\texttt{sqft_living}^2 + b_3\\texttt{bedrooms} + b_4 \\texttt{sqft_living}*\\texttt{bedrooms} + ...$$\n",
        "\n",
        "[Note that you cannot interpret $b_1$, $b_2$, $b_3$, and $b_4$ in isolation.]\n",
        "\n",
        "In our baseline prediction rules we will include squares of all \"numeric\" variable and include the interaction of `sqft_living` with `bedrooms` and with `bathrooms`"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's add some terms to try to capture nonlinearity if there is any."
      ],
      "metadata": {
        "id": "z4omAKDfYqsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline model. Quadratic in all continuous variables and interaction between\n",
        "# sqft_living and bedrooms and bathrooms\n",
        "\n",
        "base = (\"price ~ poly(bathrooms, degree=2, raw=True) + poly(bedrooms, degree=2, raw=True)\"\n",
        "             \" + poly(sqft_living, degree=2, raw=True) + poly(sqft_lot, degree=2, raw=True) + poly(floors, degree=2, raw=True) \"\n",
        "            \"+ waterfront + poly(view, degree=2, raw=True) + poly(condition, degree=2, raw=True) + \"\n",
        "            \"poly(yr_built, degree=2, raw=True) + poly(yr_renovated, degree=2, raw=True) + C(renovated_flag) + C(basement_flag)\"\n",
        "            \" + sqft_living:(bedrooms+bathrooms)\")\n",
        "\n",
        "# Create variables based on model defined in formula\n",
        "y, X = model_matrix(base, data)\n",
        "n, p_base = X.shape\n",
        "\n",
        "# Outcome variable for log models\n",
        "logy = data['log_price']"
      ],
      "metadata": {
        "id": "I9h8ciYZgYoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline regression for price\n",
        "baselm = perform_cross_validation(LinearRegression(), X, y,\n",
        "                                  scoring=scoring_lev,\n",
        "                                  cvsplit=cvsplit,\n",
        "                                  benchMSE=benchMSE,\n",
        "                                  benchMAE=benchMAE,\n",
        "                                  p=p_base)\n",
        "model_results = update_model_results(model_results, 'Baseline LM', baselm, p_base, p_base)\n",
        "\n",
        "# Baseline regression for log-price\n",
        "baseloglm = perform_cross_validation(LinearRegression(), X, logy,\n",
        "                                  scoring=scoring_log,\n",
        "                                  cvsplit=cvsplit,\n",
        "                                  benchMSE=benchMSE,\n",
        "                                  benchMAE=benchMAE,\n",
        "                                  p=p_base)\n",
        "model_results = update_model_results(model_results, 'Baseline logLM', baseloglm, p_base, p_base)\n"
      ],
      "metadata": {
        "id": "NmFRUOF8fPBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otNhg3Vtd5Bg"
      },
      "source": [
        "Not bad. Both models are a sizeable improvement relative to the simple sample mean or median.\n",
        "\n",
        "Let's look at the `log_price` model refit using the entire dataset in more detail."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GVetOXJ5d4Zi"
      },
      "outputs": [],
      "source": [
        "model = sm.OLS(logy, X)\n",
        "result = model.fit(cov_type='HC3')  # cov_type = 'HC3' computes specification robust standard errors\n",
        "print(result.summary())\n",
        "\n",
        "print('\\n')\n",
        "pred_err = result.resid\n",
        "print(\"RMSE of model: \", np.sqrt(np.mean(pred_err**2)))\n",
        "print('\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TTaNZEQYhdxm"
      },
      "source": [
        "**Questions:**\n",
        "\n",
        "1. How does the reported $R^2$ relate to the CV $R^2$?\n",
        "2. What does the reported RMSE mean?\n",
        "3. How does `sqft_living` relate to the `log_price` prediction? (Ask ChatGPT and see if it gets it right. The last time I tried it was close but not perfect.)\n",
        "\n",
        "A useful way to think about gauging how variables relate to predictions is just to probe the rule by predicting at some values of interest. This can be especially useful for black-box prediction rules.\n",
        "\n",
        "Let's specifically look at 2000 vs 2100 square feet and 4 vs 5 bedrooms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAfWUw9Mvhlw"
      },
      "outputs": [],
      "source": [
        "newX = pd.DataFrame(columns = X.columns)\n",
        "newX = newX._append(X.iloc[125]) # Observation with a 2.5 bathroom, 4 bedroom, 2000 square foot house\n",
        "newX = pd.DataFrame(np.repeat(newX.values, 4, axis=0))\n",
        "newX.columns = X.columns\n",
        "newX.iloc[1,5] = np.log(2100)\n",
        "newX.iloc[1,6] = np.log(2100)**2\n",
        "newX.iloc[1,22] = 4*np.log(2100)\n",
        "newX.iloc[1,23] = 2.5*np.log(2100)\n",
        "newX.iloc[2,3] = 5\n",
        "newX.iloc[2,4] = 5**2\n",
        "newX.iloc[2,22] = 5*np.log(2000)\n",
        "newX.iloc[3,3] = 5\n",
        "newX.iloc[3,4] = 5**2\n",
        "newX.iloc[3,5] = np.log(2100)\n",
        "newX.iloc[3,6] = np.log(2100)**2\n",
        "newX.iloc[3,22] = 5*np.log(2100)\n",
        "newX.iloc[3,23] = 2.5*np.log(2100)\n",
        "\n",
        "# Predicted log prices for our four hypothetical houses\n",
        "yhat = result.predict(newX)\n",
        "print('Difference in predicted log(price) 2100 vs 2000 sqft (4 beds):', yhat[1]-yhat[0])\n",
        "print('Difference in predicted log(price) 2100 vs 2000 sqft (5 beds):', yhat[3]-yhat[2])\n",
        "print('Difference in predicted log(price) 4 vs 5 beds (2000 sqft):', yhat[2]-yhat[0])\n",
        "print('Difference in predicted log(price) 4 vs 5 beds (2100 sqft):', yhat[3]-yhat[1])\n",
        "print('\\n')\n",
        "print('Difference in predicted price 2100 vs 2000 sqft (4 beds):', np.exp(yhat[1])-np.exp(yhat[0]))\n",
        "print('Difference in predicted price 2100 vs 2000 sqft (5 beds):', np.exp(yhat[3])-np.exp(yhat[2]))\n",
        "print('Difference in predicted price 4 vs 5 beds (2000 sqft):', np.exp(yhat[2])-np.exp(yhat[0]))\n",
        "print('Difference in predicted price 4 vs 5 beds (2100 sqft):', np.exp(yhat[3])-np.exp(yhat[1]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXHdRh2sykGy"
      },
      "source": [
        "# Baseline linear models: LAV regression\n",
        "\n",
        "We can run least absolute values regression using `sklearn`'s `QuantileRegressor`. We're still evaluation models based on 5-fold cross-validation using our previously defined splits."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_pipeline(StandardScaler(), QuantileRegressor(alpha = 0, solver = 'highs-ds'))\n",
        "# Lots of learners work best with variables on a common scale. StandardScaler()\n",
        "# standardizes the data. The pipeline is going to standardize before running\n",
        "# the quantile regression.\n",
        "\n",
        "# LAV regression for price\n",
        "baseqr = perform_cross_validation(model, X, y.to_numpy().ravel(),\n",
        "                                  scoring=scoring_lev,\n",
        "                                  cvsplit=cvsplit,\n",
        "                                  benchMSE=benchMSE,\n",
        "                                  benchMAE=benchMAE,\n",
        "                                  p=p_base)\n",
        "model_results = update_model_results(model_results, 'Baseline LAV', baseqr, p_base, p_base)\n",
        "\n",
        "# LAV regression for log-price\n",
        "baselogqr = perform_cross_validation(model, X, logy,\n",
        "                                  scoring=scoring_log,\n",
        "                                  cvsplit=cvsplit,\n",
        "                                  benchMSE=benchMSE,\n",
        "                                  benchMAE=benchMAE,\n",
        "                                  p=p_base)\n",
        "model_results = update_model_results(model_results, 'Baseline logLAV', baselogqr, p_base, p_base)\n"
      ],
      "metadata": {
        "id": "8XxT-RTCi17n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TEmA4oEIV0gp"
      },
      "source": [
        "# A More Flexible Model\n",
        "\n",
        "Maybe we haven't captured all the nonlinearity with our quadratic polynomials. Maybe there are interactions between variables besides the couple we thought about (`sqft_living` with `bedrooms` and `bathrooms`).\n",
        "\n",
        "Let's try a more elaborate model."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify model as formula\n",
        "flex = (\"price ~ poly(bathrooms, degree=4, raw=True) + poly(bedrooms, degree=4, raw=True)\"\n",
        "             \" + poly(sqft_living, degree=6, raw=True) + poly(sqft_lot, degree=4, raw=True) + poly(floors, degree=4, raw=True)\"\n",
        "             \" + waterfront + C(view) + C(condition)\"\n",
        "             \" + poly(yr_built, degree=4, raw=True) + poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag)\"\n",
        "             \" + poly(bathrooms, degree=4, raw=True):(poly(bedrooms, degree=4, raw=True)\"\n",
        "             \" + poly(sqft_living, degree=6, raw=True) + poly(sqft_lot, degree=4, raw=True) + poly(floors, degree=4, raw=True)\"\n",
        "             \" + waterfront + C(view) + C(condition)\"\n",
        "             \" + poly(yr_built, degree=4, raw=True) + poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + poly(bedrooms, degree=4, raw=True):(poly(sqft_living, degree=6, raw=True)\"\n",
        "             \" + poly(sqft_lot, degree=4, raw=True) + poly(floors, degree=4, raw=True)\"\n",
        "             \" + waterfront + C(view) + C(condition)\"\n",
        "             \" + poly(yr_built, degree=4, raw=True) + poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + poly(sqft_living, degree=6, raw=True):(poly(sqft_lot, degree=4, raw=True) + poly(floors, degree=4, raw=True)\"\n",
        "             \" + waterfront + C(view) + C(condition)\"\n",
        "             \" + poly(yr_built, degree=4, raw=True) + poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + poly(sqft_lot, degree=4, raw=True):(poly(floors, degree=4, raw=True)\"\n",
        "             \" + waterfront + C(view) + C(condition)\"\n",
        "             \" + poly(yr_built, degree=4, raw=True) + poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + poly(floors, degree=4, raw=True):(waterfront + C(view) + C(condition)\"\n",
        "             \" + poly(yr_built, degree=4, raw=True) + poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + waterfront:(C(view) + C(condition)\"\n",
        "             \" + poly(yr_built, degree=4, raw=True) + poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + C(view):(C(condition) + poly(yr_built, degree=4, raw=True) + poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + C(condition):(poly(yr_built, degree=4, raw=True) + poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + poly(yr_built, degree=4, raw=True):(poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + poly(yr_renovated, degree=4, raw=True):(C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + C(renovated_flag):C(basement_flag)\")\n",
        "\n",
        "# Create variables based on model defined in formula\n",
        "y, X = model_matrix(flex, data)\n",
        "n, p_flex = X.shape\n",
        "\n",
        "# Outcome variable for log models\n",
        "logy = data['log_price']"
      ],
      "metadata": {
        "id": "DPqQAWkaj3gm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's run our more flexible model and see how it does according to 5-Fold CV."
      ],
      "metadata": {
        "id": "aG-axCnSkYc0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = make_pipeline(StandardScaler(), LinearRegression())\n",
        "# Lots of learners work best with variables on a common scale. StandardScaler()\n",
        "# standardizes the data. This can be very important with high order polynomials.\n",
        "\n",
        "# Regression for price from flexible model\n",
        "flexlm = perform_cross_validation(model, X, y,\n",
        "                                  scoring=scoring_lev,\n",
        "                                  cvsplit=cvsplit,\n",
        "                                  benchMSE=benchMSE,\n",
        "                                  benchMAE=benchMAE,\n",
        "                                  p=p_flex)\n",
        "\n",
        "# Regression for log-price from flexible model\n",
        "flexloglm = perform_cross_validation(model, X, logy,\n",
        "                                  scoring=scoring_log,\n",
        "                                  cvsplit=cvsplit,\n",
        "                                  benchMSE=benchMSE,\n",
        "                                  benchMAE=benchMAE,\n",
        "                                  p=p_flex)\n"
      ],
      "metadata": {
        "id": "1KhNrULakdg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGXS7F_PRkWa"
      },
      "source": [
        "**Aside:** I cheated in my definition of the scorer for the log models to prevent numeric issues in silly models (like this one). The actual performance is much worse.\n",
        "\n",
        "We're not going to add these performance metrics to our table because they're awful and make the table unreadable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFe4KqD-kHh7"
      },
      "source": [
        "It looks like the flexible model does a really bad job.\n",
        "\n",
        "**Questions:**\n",
        "1. I'm only showing validation sample performance measures. How do we think in-sample validation measures line up?\n",
        "2. Does the very poor validation performance of the \"interactions\" model mean nothing in the model adds predictive power beyond the other models?\n",
        "3. Are we sure we have tried everything we want? There are lots of \"intermediate\" models?\n",
        "4. Should we have even more interactions or allow for higher order nonlinearity? How do we specify all the choices?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A38qnsL2krcX"
      },
      "source": [
        "## Lasso\n",
        "\n",
        "A popular approach to estimating linear models when there are many potential variables is the *Lasso*.\n",
        "\n",
        "Recall that conventional linear model estimates are obtained by solving\n",
        "\n",
        "$$\\min \\sum_{i} (y_i - b_0 - b_1 X_1 - ... - b_p X_p)^2$$\n",
        "\n",
        "where the sum is over all observations in the training data. That is, we try to find the linear prediction rule for $Y$ that is as close as possible to $Y$ in the training data.\n",
        "\n",
        "Lasso solves a similar problem\n",
        "\n",
        "$$\\min \\sum_{i} (y_i - b_0 - b_1 X_1 - ... - b_p X_p)^2 + \\lambda \\sum_j |b_j|.$$\n",
        "\n",
        "The key thing we have added is a *penalty term* $\\lambda \\sum_j |b_j|$. Intuitively, this penalty says that if you want to move a coefficient $b_j$ away from 0 to improve the in-sample fit, you also have to pay a cost introduced by the penalty term.\n",
        "\n",
        "In practice, the presence of the penalty may lead to variables being excluded from the model. Intuitively, if the benefit of moving a $b_j$ away from 0 is smaller than the cost, the coefficient will be left at 0.\n",
        "\n",
        "When we do Lasso, we have to choose the *tuning parameter* $\\lambda$ which controls the cost of increasing the size of coefficients. We choose $\\lambda$ by trying several values and choosing the best according to cross-validation (or just validation).\n",
        "\n",
        "[Aside: There are MANY other penalized regression procedures. Another popular one is Ridge. There's also grouped Lasso, Elastic Net, ... The basic idea of all of them is to guard against overfitting by penalizing large values of coefficients. Not all of them do variable selection.]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUdqnJ_xoCK7"
      },
      "source": [
        "Let's look at how Lasso does in our example. We have to start from a model that has the universe of variables that could matter. We'll start from both the polynomial and interactive models and see what happens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_OZBz1R8o09o"
      },
      "source": [
        "# Lasso with baseline model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZORFBIM873sS"
      },
      "source": [
        "We're going to repeat the exercise but now use Lasso. Lasso requires us to choose how much we want it \"to cost\" to increase a parameter's magnitude (i.e. to move it away from zero). We're going to choose this by trying a bunch out and taking the best one. Ideally, we'd do this with another validation dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For our Lasso models, we are going to repeatedly apply the same steps. Let's write some functions so we don't have to keep typing the same things."
      ],
      "metadata": {
        "id": "QKQO0Ni6nWI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def perform_gridsearchcv(model, parameters, scoring, X, y, cvsplit, refit_metric='mse'):\n",
        "    grid_search = GridSearchCV(model, parameters, scoring=scoring, refit=refit_metric, cv=cvsplit)\n",
        "    grid_search.fit(X, y)\n",
        "    return grid_search\n",
        "\n",
        "def extract_performance_metrics(grid_search, benchMSE, benchMAE, p):\n",
        "\n",
        "    lranks = grid_search.cv_results_.get(f'rank_test_mse')\n",
        "    cvmse = -grid_search.cv_results_.get(f'mean_test_mse')\n",
        "    cvmae = -grid_search.cv_results_.get(f'mean_test_mae')\n",
        "    bestmse = cvmse[lranks == 1].min()\n",
        "    bestmae = cvmae[lranks == 1].min()\n",
        "\n",
        "    best_model = grid_search.best_estimator_\n",
        "\n",
        "    # Access Lasso model from the pipeline\n",
        "    lasso_model = best_model.named_steps['lasso']\n",
        "\n",
        "    # Retrieve coefficients\n",
        "    coefficients = lasso_model.coef_\n",
        "    p_use = sum(coefficients != 0)\n",
        "\n",
        "    # Print out summary of performance\n",
        "    print('CV RMSE: {m1:=.2f}; CV R2: {m2:=.3f}'\n",
        "      .format(m1=np.sqrt(bestmse),\n",
        "              m2=1-(bestmse/benchMSE)))\n",
        "\n",
        "    print('CV MAE: {m1:=.2f}; CV MAE R2: {m2:=.3f}'\n",
        "      .format(m1=bestmae,\n",
        "              m2=1-(bestmae/benchMAE)))\n",
        "\n",
        "    print(\"p: \", p)\n",
        "    print(\"p_use: \", p_use)\n",
        "\n",
        "    return bestmse, bestmae, p_use\n",
        "\n",
        "def add_to_results_table(model_results, model_name, bestmse, bestmae, benchMSE, benchMAE, p, p_use):\n",
        "\n",
        "    model_results = model_results._append({\n",
        "        'Model': model_name,\n",
        "        'RMSE': np.sqrt(bestmse),\n",
        "        'R2 - MSE': 1 - (bestmse / benchMSE),\n",
        "        'MAE': bestmae,\n",
        "        'R2 - MAE': 1 - (bestmae / benchMAE),\n",
        "        'p': p,\n",
        "        'p_use': p_use\n",
        "    }, ignore_index=True)\n",
        "\n",
        "    return model_results\n",
        "\n",
        "def plot_performance(grid_search, title='Performance Metrics'):\n",
        "\n",
        "    lambdas = grid_search.cv_results_.get('param_lasso__alpha').tolist()\n",
        "    cvrmse = np.sqrt(-grid_search.cv_results_.get('mean_test_mse'))\n",
        "    cvmae = -grid_search.cv_results_.get('mean_test_mae')\n",
        "    best_lambda = grid_search.best_params_.get('lasso__alpha')\n",
        "\n",
        "    # Make plot\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.semilogx(lambdas, cvrmse, label='CV RMSE')\n",
        "    plt.semilogx(lambdas, cvmae, label='CV MAE')\n",
        "    plt.axvline(best_lambda, linestyle=\"--\", color=\"black\", label=\"CV estimate\")\n",
        "    plt.xlabel(r\"$\\lambda$\")\n",
        "    plt.ylabel(\"Error Estimate\")\n",
        "    plt.title(title)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "DIGudIEVnZd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to start from the same baseline model we used above."
      ],
      "metadata": {
        "id": "7My-ujMuoCGS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create variables from our baseline model (defined in formula base)\n",
        "y, X = model_matrix(base, data)\n",
        "n, p_base = X.shape\n",
        "\n",
        "# Outcome variable for log models\n",
        "logy = data['log_price']"
      ],
      "metadata": {
        "id": "EEHU8F-cn-SP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're now going to estimate and evaluate our baseline model for `price` and for `log_price` using the same five fold cross-validation splits."
      ],
      "metadata": {
        "id": "TvBRwIuqoUn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sequence of penalty parameters to try\n",
        "ub = np.std(y)*np.sqrt(2*np.log(2*p_base/.05))/np.sqrt(n)\n",
        "lambdas = np.geomspace(start=ub/100, stop=ub, num=25)\n",
        "\n",
        "# Let's do cross-validation to choose a value for lambda\n",
        "model = make_pipeline(StandardScaler(), Lasso())\n",
        "# \"StandardScaler\" is important here. It standardizes the data. Because Lasso\n",
        "# depends on the coefficients of the linear model and the coefficients depend\n",
        "# on the scale of the X's, you can get very different answers depending on how\n",
        "# you choose to scale the variables.\n",
        "\n",
        "# Cross validation. Set up parameter we are trying to optimize.\n",
        "parameters = {'lasso__alpha':lambdas.ravel()}\n",
        "\n",
        "baselas = perform_gridsearchcv(model, parameters, scoring=scoring_lev,\n",
        "                               X=X, y=y, cvsplit=cvsplit, refit_metric='mse')\n",
        "\n",
        "baselasmse, baselasmae, baselasp = extract_performance_metrics(baselas, benchMSE, benchMAE, p_base)\n",
        "\n",
        "model_results = add_to_results_table(model_results, 'Baseline Lasso', baselasmse, baselasmae, benchMSE, benchMAE, p_base, baselasp)\n",
        "\n",
        "plot_performance(baselas, title='Baseline Lasso CV')"
      ],
      "metadata": {
        "id": "KCJdnXRGoZpW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see which variables the Lasso model uses."
      ],
      "metadata": {
        "id": "8Oy_RAq9s8wR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = baselas.best_estimator_\n",
        "\n",
        "# Access Lasso model from the pipeline\n",
        "lasso_model = best_model.named_steps['lasso']\n",
        "\n",
        "# Which variables do we use\n",
        "print(X.columns[lasso_model.coef_ != 0])\n",
        "\n",
        "# Which do we drop\n",
        "print(X.columns[lasso_model.coef_ == 0])\n",
        "\n"
      ],
      "metadata": {
        "id": "GsWUv2SIsvFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYElwtbAwIUB"
      },
      "source": [
        "Let's change and look at `log_price` as the dependent variable."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Log price model\n",
        "\n",
        "# Sequence of penalty parameters to try\n",
        "ub = np.std(logy)*np.sqrt(2*np.log(2*p_base/.05))/np.sqrt(n)\n",
        "lambdas = np.geomspace(start=ub/100, stop=ub, num=25)\n",
        "\n",
        "# Cross validation. Set up parameter we are trying to optimize.\n",
        "parameters = {'lasso__alpha':lambdas.ravel()}\n",
        "\n",
        "baseloglas = perform_gridsearchcv(model, parameters, scoring=scoring_log,\n",
        "                               X=X, y=logy, cvsplit=cvsplit, refit_metric='mse')\n",
        "\n",
        "baseloglasmse, baseloglasmae, baseloglasp = extract_performance_metrics(baseloglas,\n",
        "                                                                        benchMSE,\n",
        "                                                                        benchMAE,\n",
        "                                                                        p_base)\n",
        "\n",
        "model_results = add_to_results_table(model_results, 'Baseline logLasso',\n",
        "                                     baseloglasmse, baseloglasmae,\n",
        "                                     benchMSE, benchMAE, p_base, baseloglasp)\n",
        "\n",
        "plot_performance(baseloglas, title='Baseline logLasso CV')\n"
      ],
      "metadata": {
        "id": "7v7hRwR1tQbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see which variables this Lasso model for `log_price` with cost parameter chosen by looking at CV `price` prediction uses."
      ],
      "metadata": {
        "id": "dcXNRQx2uFoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = baseloglas.best_estimator_\n",
        "\n",
        "# Access Lasso model from the pipeline\n",
        "lasso_model = best_model.named_steps['lasso']\n",
        "\n",
        "# Variables in the baseline log model estimated via lasso and estimated coefficients\n",
        "baseloglas_coefs = pd.DataFrame(data={'Variable Names': X.columns[lasso_model.coef_ != 0], 'Coefficient': lasso_model.coef_[lasso_model.coef_ != 0]})\n",
        "print(baseloglas_coefs.to_markdown())\n"
      ],
      "metadata": {
        "id": "VhESnZQnuFNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ndr5MDAXwT-8"
      },
      "source": [
        "# Lasso with flexible model\n",
        "\n",
        "**(This block takes ~ 5 minutes to run.)**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're just going to repeat now, but use the flexible model in place of the baseline model."
      ],
      "metadata": {
        "id": "1TOS-7YXujgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create variables from our flexible model (defined in formula flex)\n",
        "y, X = model_matrix(flex, data)\n",
        "n, p_flex = X.shape\n",
        "\n",
        "# Outcome variable for log models\n",
        "logy = data['log_price']"
      ],
      "metadata": {
        "id": "ODcCF1fcupCg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're now going to build the Lasso prediction models."
      ],
      "metadata": {
        "id": "nhHAV23Qu3Jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Price model\n",
        "\n",
        "# Sequence of penalty parameters to try\n",
        "ub = np.std(y)*np.sqrt(2*np.log(2*p_flex/.05))/np.sqrt(n)\n",
        "lambdas = np.geomspace(start=ub/10, stop=ub, num=15)\n",
        "\n",
        "# Let's do cross-validation in the training data to choose a value for lambda\n",
        "model = make_pipeline(StandardScaler(), Lasso())\n",
        "# \"StandardScaler\" is important here. It standardizes the data. Because Lasso\n",
        "# depends on the coefficients of the linear model and the coefficients depend\n",
        "# on the scale of the X's, you can get very different answers depending on how\n",
        "# you choose to scale the variables.\n",
        "\n",
        "# Cross validation. Set up parameter we are trying to optimize.\n",
        "parameters = {'lasso__alpha':lambdas.ravel()}\n",
        "\n",
        "flexlas = perform_gridsearchcv(model, parameters, scoring=scoring_lev,\n",
        "                               X=X, y=y, cvsplit=cvsplit, refit_metric='mse')\n",
        "\n",
        "flexlasmse, flexlasmae, flexlasp = extract_performance_metrics(flexlas, benchMSE, benchMAE, p_flex)\n",
        "\n",
        "model_results = add_to_results_table(model_results, 'Flexible Lasso', flexlasmse,\n",
        "                                     flexlasmae, benchMSE, benchMAE, p_flex, flexlasp)\n",
        "\n",
        "plot_performance(flexlas, title='Flexible Lasso CV')\n"
      ],
      "metadata": {
        "id": "yhJb_mlQu2ud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Log-price model\n",
        "\n",
        "# Sequence of penalty parameters to try\n",
        "ub = np.std(logy)*np.sqrt(2*np.log(2*p_flex/.05))/np.sqrt(n)\n",
        "lambdas = np.geomspace(start=ub/10, stop=ub, num=15)\n",
        "\n",
        "# Cross validation. Set up parameter we are trying to optimize.\n",
        "parameters = {'lasso__alpha':lambdas.ravel()}\n",
        "\n",
        "flexloglas = perform_gridsearchcv(model, parameters, scoring=scoring_log,\n",
        "                               X=X, y=logy, cvsplit=cvsplit, refit_metric='mse')\n",
        "\n",
        "flexloglasmse, flexloglasmae, flexloglasp = extract_performance_metrics(flexloglas, benchMSE, benchMAE, p_flex)\n",
        "\n",
        "model_results = add_to_results_table(model_results, 'Flexible logLasso', flexloglasmse,\n",
        "                                     flexloglasmae, benchMSE, benchMAE, p_flex, flexloglasp)\n",
        "\n",
        "plot_performance(flexlas, title='Flexible logLasso CV')"
      ],
      "metadata": {
        "id": "CU7p1fnsznrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the estimated model for `log_price`."
      ],
      "metadata": {
        "id": "QwKh-FsDygED"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5lJx_iBc6Li"
      },
      "outputs": [],
      "source": [
        "best_model = flexloglas.best_estimator_\n",
        "\n",
        "# Access Lasso model from the pipeline\n",
        "lasso_model = best_model.named_steps['lasso']\n",
        "\n",
        "# Variables in the flexible log model estimated via lasso and estimated coefficients\n",
        "flexloglas_coefs = pd.DataFrame(data={'Variable Names': X.columns[lasso_model.coef_ != 0], 'Coefficient': lasso_model.coef_[lasso_model.coef_ != 0]})\n",
        "print(flexloglas_coefs.to_markdown())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "incLsjWDdgXK"
      },
      "source": [
        "**Questions:**\n",
        "\n",
        "1. We have a list of variables and coefficients. Is the model particularly interpretable?\n",
        "2. Should we conclude we have the \"correct\" variables?\n",
        "3. What if there are things we didn't try? How far should we go? Maybe we should have looked at higher order interactions (i.e. multiplying more than two variables together), other transformations, ...\n",
        "\n",
        "**Miscellaneous comments:**\n",
        "\n",
        "When we moved to Lasso, we could have included `sqft_above` and `sqft_basement` in the model along with `sqft_living` and let the data decide which are more useful. (For example, maybe basement square feet are not as valuable as above ground square feet, which can't be picked up when only `sqft_living` is included.)\n",
        "\n",
        "We haven't considered `statezip` or `city` yet.\n",
        "\n",
        "Penalized quantile regression (e.g. \"lasso for LAV\") exists and is available in `sklearn`'s `QuantileRegressor`.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhYex1DXhVK3"
      },
      "source": [
        "**Final Comment on Linear Models**\n",
        "\n",
        "Linear (and related) models are useful, but they do not do *feature learning*. I.e. they rely on the analyst to specify all the relevant features **and their transformations** before building the predictive model. In settings where there is strong intuition for what is important and how it relates to the target, this is not a huge problem. In setting with limited data, simple models (e.g. ignore transformations of continuous regressors and just include them as is) tend to work well.\n",
        "\n",
        "Rather than require pre-specification of all input features, most ML methods leverage the power of machines and clever algorithms to simultaneously **learn feature representations** and build the model for making predictions.\n",
        "\n",
        "The ability of ML algorithms to learn feature representations without needing prespecification is practically very important in complex environments or settings with large amounts of data. Even in our relatively simple house price example, we can already see that relying on prespecifying everything can be daunting.\n",
        "\n",
        "Often (though not always) these models outperform methods that do not do feature learning in terms of predictive performance. Even if they do not \"beat\" more traditional methods, they almost always come with the benefit of alleviating the analyst's burden of choice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cerbcZ_XzuU6"
      },
      "source": [
        "# Regression Trees\n",
        "\n",
        "Rather than try to build all the relevant features ourselves. Let's fit a regression *tree* instead.\n",
        "\n",
        "The basic idea of a regression tree is to chop the data into rectangles based on the raw input variables and then fit a simple model - we'll just use the sample mean.\n",
        "\n",
        "The way we'll chop things into rectangles is by making binary splits of the data. By making chops of the data based on binary decisions, we simultaneously uncover nonlinearity (including interactions) and which variables are most informative in making our predictions. We do not have to prespecify the types of nonlinearity we think might matter, we just learn it from the data.\n",
        "\n",
        "Rather than try to talk about it, it's probably easier to just see how it works in our little example.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_g6_LEPXjnIm"
      },
      "source": [
        "Let's start by pulling together a dataset that we will use for our trees. We'll focus on the same variables we used in our linear models. Note that we'll leave `sqft_above` and `sqft_basement` in as the tree can choose which representation of square footage it wants to use to best predict the outcome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OQo8jId7IMWn"
      },
      "outputs": [],
      "source": [
        "data_tree = data.drop(columns=['city','statezip','renovated_flag','basement_flag'])\n",
        "\n",
        "# Let's make our outcome variables and predictors\n",
        "X = data_tree.drop(columns=['price','log_price'])\n",
        "y = data_tree['price']\n",
        "logy = data_tree['log_price']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDg3HYapJJty"
      },
      "source": [
        "Because we're just illustrating, we'll start by making a tree with just one split using the full data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FdtEVC6nNa9b"
      },
      "outputs": [],
      "source": [
        "# Let's fit a tree to price with 1 split = 2 leaves\n",
        "tree1 = DecisionTreeRegressor(max_leaf_nodes = 2)\n",
        "tree1.fit(X, y)\n",
        "plot_tree(tree1, feature_names=X.columns)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eypRN6H0kVzr"
      },
      "source": [
        "The first split in our tree is at `sqft_living` = $exp$(7.978) = 2916. We predict houses less than or equal to 2916 square feet to have price \\$457,977 and houses with more than 2916 square feet to have price \\$993,690. (The predictions are just the sample mean price of houses smaller than 2916 square feet and sample mean of price of houses larger than 2916 square feet.)\n",
        "\n",
        "This split was determined by looking at every possible split of every possible variable and asking which split provides the best prediction rule for `price` in the terms of having the minimum MSE.\n",
        "\n",
        "What happens when we want to have a prediction rule with 3 terminal nodes?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YPO7O58jN5bu"
      },
      "outputs": [],
      "source": [
        "# Let's fit a tree with 2 splits = 3 leaves\n",
        "tree2 = DecisionTreeRegressor(max_leaf_nodes = 3)\n",
        "tree2.fit(X, y)\n",
        "plot_tree(tree2, feature_names=X.columns)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pyq2kiYTldFF"
      },
      "source": [
        "We see that we have introduced another split along `sqft_living`. That we would split again on this variable was not predetermined. We tried every possible split along every possible variable of the subsample of houses with `sqft_living` $\\leq$ 2916 and every possible split along every possible variable of the subsample of houses with `sqft_living` $>$ 2916. Of all these possible choices, the best split, in the sense of reducing MSE of predicting `price`, was to split again at `sqft_living` = $\\exp$(8.723) = 6140.\n",
        "\n",
        "Our prediction rule now has three points, houses $\\leq$ 2915 square feet are predicted to have price \\$457,977. Houses with 2915 $<$ `sqft_living` $\\leq$ 6140 are predicted to have price \\$954,056. Houses greater than 6143 square feet are predicted to have price \\$2,873,812.\n",
        "\n",
        "We can, of course, keep going.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVCJ4mGNRb9u"
      },
      "outputs": [],
      "source": [
        "# Make the figure bigger than default so it's easier to read\n",
        "width = 10\n",
        "height = 7\n",
        "plt.figure(figsize=(width, height))\n",
        "\n",
        "# Let's fit a tree with 3 splits = 4 leaves\n",
        "tree3 = DecisionTreeRegressor(max_leaf_nodes = 4)\n",
        "tree3.fit(X, y)\n",
        "plot_tree(tree3, feature_names=X.columns)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9M6TV925WNhU"
      },
      "source": [
        "Let's make one more plot to show how the regression tree is uncovering nonlinearity without having to prespecify transformations of the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHAwD6EHWX6x"
      },
      "outputs": [],
      "source": [
        "# Predict\n",
        "yfit = tree3.predict(X)\n",
        "xplot = np.sort(X['sqft_living'])\n",
        "yplot = np.sort(yfit)\n",
        "\n",
        "# Plot\n",
        "plt.figure()\n",
        "plt.plot(xplot, yplot, linewidth=2)\n",
        "plt.xlabel(\"Square Footage\")\n",
        "plt.ylabel(\"Price\")\n",
        "plt.title(\"Decision Tree Regression with Four Leaves\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nk14AtqznT7Z"
      },
      "source": [
        "Basic tree models correspond to *step functions*. Step functions are simple, though not necessarily the best for lots of outcomes where we think *continuity* makes sense. We'll worry about this later."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UoECI_TnmDN"
      },
      "source": [
        "Let's look at one more larger tree to see how we also pick up interactions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmvCuQHomqQY"
      },
      "outputs": [],
      "source": [
        "# Make the figure bigger than default so it's easier to read\n",
        "width = 14\n",
        "height = 10\n",
        "plt.figure(figsize=(width, height))\n",
        "\n",
        "# Let's fit a tree with 8 leaves\n",
        "tree8 = DecisionTreeRegressor(max_leaf_nodes = 8)\n",
        "tree8.fit(X, y)\n",
        "plot_tree(tree8, feature_names=X.columns)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUzv16fB1H8T"
      },
      "source": [
        "We can (and will) continue, though we'll stop showing the picture every time. The basic idea of trees is very simple. We keep make binary splits of the data where each split improves the fit to the training data. We can fit the training data very well with enough splits - though that's unlikely to generalize well.\n",
        "\n",
        "We choose which tree we want to use by (cross-) validation. There are lots of ways we could specify and train trees. Rather than look at number of leaves, we could look at depth. We might want to specify a minimum leaf size to avoid leaves with very few observations.\n",
        "\n",
        "We're just going to look at cross-validating over number of leaves and not worry about other details."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll again define some functions for repetitive tasks."
      ],
      "metadata": {
        "id": "rWguWQhu0v9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_tree_metrics(grid_search, benchMSE, benchMAE):\n",
        "\n",
        "    lranks = grid_search.cv_results_.get(f'rank_test_mse')\n",
        "    cvmse = -grid_search.cv_results_.get(f'mean_test_mse')\n",
        "    cvmae = -grid_search.cv_results_.get(f'mean_test_mae')\n",
        "    bestmse = cvmse[lranks == 1].min()\n",
        "    bestmae = cvmae[lranks == 1].min()\n",
        "\n",
        "    p_use = grid_search.best_params_.get('max_leaf_nodes')\n",
        "\n",
        "    # Print out summary of performance\n",
        "    print('CV RMSE: {m1:=.2f}; CV R2: {m2:=.3f}'\n",
        "      .format(m1=np.sqrt(bestmse),\n",
        "              m2=1-(bestmse/benchMSE)))\n",
        "\n",
        "    print('CV MAE: {m1:=.2f}; CV MAE R2: {m2:=.3f}'\n",
        "      .format(m1=bestmae,\n",
        "              m2=1-(bestmae/benchMAE)))\n",
        "\n",
        "    print(\"p_use: \", p_use)\n",
        "\n",
        "    return bestmse, bestmae, p_use\n",
        "\n",
        "def plot_tree_performance(grid_search):\n",
        "\n",
        "    leaves = grid_search.cv_results_.get('param_max_leaf_nodes')\n",
        "    leaves = leaves.tolist()\n",
        "\n",
        "    lranks = grid_search.cv_results_.get('rank_test_mse')\n",
        "    cvmse = -grid_search.cv_results_.get('mean_test_mse')\n",
        "    cvmae = -grid_search.cv_results_.get('mean_test_mae')\n",
        "\n",
        "    plt.plot(leaves, np.sqrt(cvmse), label = 'RMSE')\n",
        "    plt.plot(leaves, cvmae, label = 'MAE')\n",
        "    plt.axvline(grid_search.best_params_.get('max_leaf_nodes'),\n",
        "                linestyle=\"--\", color=\"black\", label=\"CV estimate\")\n",
        "    plt.xlabel(\"Number of leaves\")\n",
        "    plt.ylabel(\"Cross-validation RMSE\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "fqSsDPL30y9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameter we want to choose based on cross-validation performance - number of leaves\n",
        "parameters = {'max_leaf_nodes':range(2,101)}\n",
        "\n",
        "# Define model and do cross-validation\n",
        "tree = DecisionTreeRegressor()\n",
        "base_tree = perform_gridsearchcv(tree, parameters, scoring=scoring_lev,\n",
        "                                 X=X, y=y, cvsplit=cvsplit, refit_metric='mse')\n",
        "\n",
        "bestmse_base_tree, bestmae_base_tree, base_tree_p = extract_tree_metrics(base_tree, benchMSE, benchMAE)\n",
        "\n",
        "plot_tree_performance(base_tree)\n",
        "\n",
        "model_results = add_to_results_table(model_results, 'Decision Tree',\n",
        "                                     bestmse_base_tree, bestmae_base_tree,\n",
        "                                     benchMSE, benchMAE, '-', base_tree_p)\n",
        "\n"
      ],
      "metadata": {
        "id": "qQtJUoFvzzhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gTxMxq4ReWC"
      },
      "source": [
        "What does our estimated tree look like?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYdHsv-HRblX"
      },
      "outputs": [],
      "source": [
        "width = 15\n",
        "height = 15\n",
        "plt.figure(figsize=(width, height))\n",
        "\n",
        "# Let's plot the cv minimizing tree\n",
        "plot_tree(base_tree.best_estimator_, feature_names=X.columns)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bhlw8ChyyxlP"
      },
      "source": [
        "**We'd need a pretty big screen to see what's going on here.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYn0rol8rq2L"
      },
      "source": [
        "Looks like lots of results with similar performance and highly variable across number of leaves. Default behavior in the software allows for very small leaves. For example, we can see from the estimated tree that we have leaves with just one observation. We might want to add more stability be ruling out small leaves."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make it so each leaf must have 10 or more observations.\n",
        "# Everything else will be the same as for the baseline tree\n",
        "tree = DecisionTreeRegressor(min_samples_leaf=10)\n",
        "\n",
        "tree10 = perform_gridsearchcv(tree, parameters, scoring=scoring_lev,\n",
        "                              X=X, y=y, cvsplit=cvsplit, refit_metric='mse')\n",
        "\n",
        "bestmse_tree10, bestmae_tree10, tree10_p = extract_tree_metrics(tree10, benchMSE, benchMAE)\n",
        "\n",
        "plot_tree_performance(tree10)\n",
        "\n",
        "model_results = add_to_results_table(model_results, 'Decision Tree 10',\n",
        "                                     bestmse_tree10, bestmae_tree10,\n",
        "                                     benchMSE, benchMAE, '-', tree10_p)\n"
      ],
      "metadata": {
        "id": "ZrLcd6gM3Kp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBnP6KDUlJQh"
      },
      "source": [
        "As we did before, we can also use `log_price` as dependent variable."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# All we need to do is change the dependent variable. We'll also set things\n",
        "# back to the default with no restriction on leaf size.\n",
        "# We also need to change our scoring rule to look at predicting price, not\n",
        "# log_price\n",
        "\n",
        "# Define model and do cross-validation\n",
        "tree = DecisionTreeRegressor()\n",
        "log_tree = perform_gridsearchcv(tree, parameters, scoring=scoring_log,\n",
        "                                 X=X, y=logy, cvsplit=cvsplit, refit_metric='mse')\n",
        "\n",
        "bestmse_log_tree, bestmae_log_tree, log_tree_p = extract_tree_metrics(log_tree, benchMSE, benchMAE)\n",
        "\n",
        "plot_tree_performance(log_tree)\n",
        "\n",
        "model_results = add_to_results_table(model_results, 'Decision Tree - log',\n",
        "                                     bestmse_log_tree, bestmae_log_tree,\n",
        "                                     benchMSE, benchMAE, '-', log_tree_p)\n"
      ],
      "metadata": {
        "id": "XmYc_kY33fEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's do the same thing as before and restrict to have at least 10 observations per leaf."
      ],
      "metadata": {
        "id": "7vnoIT6v4POd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree = DecisionTreeRegressor(min_samples_leaf=10)\n",
        "\n",
        "log_tree10 = perform_gridsearchcv(tree, parameters, scoring=scoring_log,\n",
        "                              X=X, y=logy, cvsplit=cvsplit, refit_metric='mse')\n",
        "\n",
        "bestmse_log_tree10, bestmae_log_tree10, log_tree10_p = extract_tree_metrics(log_tree10, benchMSE, benchMAE)\n",
        "\n",
        "plot_tree_performance(log_tree10)\n",
        "\n",
        "model_results = add_to_results_table(model_results, 'Decision Tree 10 - log',\n",
        "                                     bestmse_log_tree10, bestmae_log_tree10,\n",
        "                                     benchMSE, benchMAE, '-', log_tree10_p)\n"
      ],
      "metadata": {
        "id": "_BsXAxCO4aPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the complete collection of our results."
      ],
      "metadata": {
        "id": "ugyC0ce14xCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_results.sort_values(by=['RMSE'])"
      ],
      "metadata": {
        "id": "17cH0R1Z40Xb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33CotEjssn8v"
      },
      "source": [
        "The tree models work a bit worse than the linear models here.\n",
        "\n",
        "So, why do people like tree models?\n",
        "\n",
        "1. They are simple and fast. They don't require much thought. Scale and monotone transformations of the features don't matter.\n",
        "2. They underlie more complex procedures that we'll talk about next.\n",
        "3. They don't require pre-specifying all the things we think might matter.\n",
        "\n",
        "Finally, remember you should try out linear models as one of your prediction rules in many cases - certainly with small numbers of observations and standard numeric data. (Relatively simple) Linear models will often work well in that setting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xce_kLuIx9pb"
      },
      "source": [
        "# Last thing - What about our categorical variables?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYjVXsio6IVR"
      },
      "source": [
        "Unordered categorical variables with many categories relative to the number of observations (so there are not many observations within each category) are a challenge to many supervised learners and one of the spots where linear models do pretty well.\n",
        "\n",
        "Let's try a couple of our models out with the categorical variables `city` and `statezip`."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will include each of `statezip` and `city` on its own. We'll also see what happens if we include all unique combinations of the two (equivalent to interacting `statezip` with `city`)."
      ],
      "metadata": {
        "id": "cuYi6uy1PmgI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['both'] = data['statezip'] + '_' + data['city']\n",
        "data['both'].value_counts()"
      ],
      "metadata": {
        "id": "j0B30VBuMZvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's just define our models."
      ],
      "metadata": {
        "id": "bJ42ab1c59Y6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "basecity = (\"price ~ poly(bathrooms, degree=2, raw=True) + poly(bedrooms, degree=2, raw=True)\"\n",
        "             \" + poly(sqft_living, degree=2, raw=True) + poly(sqft_lot, degree=2, raw=True) + poly(floors, degree=2, raw=True) \"\n",
        "            \"+ waterfront + poly(view, degree=2, raw=True) + poly(condition, degree=2, raw=True) + \"\n",
        "            \"poly(yr_built, degree=2, raw=True) + poly(yr_renovated, degree=2, raw=True) + C(renovated_flag) + C(basement_flag)\"\n",
        "            \" + sqft_living:(bedrooms+bathrooms) + C(city)\")\n",
        "\n",
        "basezip = (\"price ~ poly(bathrooms, degree=2, raw=True) + poly(bedrooms, degree=2, raw=True)\"\n",
        "             \" + poly(sqft_living, degree=2, raw=True) + poly(sqft_lot, degree=2, raw=True) + poly(floors, degree=2, raw=True) \"\n",
        "            \"+ waterfront + poly(view, degree=2, raw=True) + poly(condition, degree=2, raw=True) + \"\n",
        "            \"poly(yr_built, degree=2, raw=True) + poly(yr_renovated, degree=2, raw=True) + C(renovated_flag) + C(basement_flag)\"\n",
        "            \" + sqft_living:(bedrooms+bathrooms) + C(statezip)\")\n",
        "\n",
        "baseboth = (\"price ~ poly(bathrooms, degree=2, raw=True) + poly(bedrooms, degree=2, raw=True)\"\n",
        "             \" + poly(sqft_living, degree=2, raw=True) + poly(sqft_lot, degree=2, raw=True) + poly(floors, degree=2, raw=True) \"\n",
        "            \"+ waterfront + poly(view, degree=2, raw=True) + poly(condition, degree=2, raw=True) + \"\n",
        "            \"poly(yr_built, degree=2, raw=True) + poly(yr_renovated, degree=2, raw=True) + C(renovated_flag) + C(basement_flag)\"\n",
        "            \" + sqft_living:(bedrooms+bathrooms) + C(both)\")\n",
        "\n",
        "# Big model to try with Lasso\n",
        "flex2 = (\"price ~ poly(bathrooms, degree=4, raw=True) + poly(bedrooms, degree=4, raw=True)\"\n",
        "             \" + poly(sqft_living, degree=6, raw=True) + poly(sqft_lot, degree=4, raw=True) + poly(floors, degree=4, raw=True)\"\n",
        "             \" + waterfront + C(view) + C(condition)\"\n",
        "             \" + poly(yr_built, degree=4, raw=True) + poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag)\"\n",
        "             \" + poly(bathrooms, degree=4, raw=True):(poly(bedrooms, degree=4, raw=True)\"\n",
        "             \" + poly(sqft_living, degree=6, raw=True) + poly(sqft_lot, degree=4, raw=True) + poly(floors, degree=4, raw=True)\"\n",
        "             \" + waterfront + C(view) + C(condition)\"\n",
        "             \" + poly(yr_built, degree=4, raw=True) + poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + poly(bedrooms, degree=4, raw=True):(poly(sqft_living, degree=6, raw=True)\"\n",
        "             \" + poly(sqft_lot, degree=4, raw=True) + poly(floors, degree=4, raw=True)\"\n",
        "             \" + waterfront + C(view) + C(condition)\"\n",
        "             \" + poly(yr_built, degree=4, raw=True) + poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + poly(sqft_living, degree=6, raw=True):(poly(sqft_lot, degree=4, raw=True) + poly(floors, degree=4, raw=True)\"\n",
        "             \" + waterfront + C(view) + C(condition)\"\n",
        "             \" + poly(yr_built, degree=4, raw=True) + poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + poly(sqft_lot, degree=4, raw=True):(poly(floors, degree=4, raw=True)\"\n",
        "             \" + waterfront + C(view) + C(condition)\"\n",
        "             \" + poly(yr_built, degree=4, raw=True) + poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + poly(floors, degree=4, raw=True):(waterfront + C(view) + C(condition)\"\n",
        "             \" + poly(yr_built, degree=4, raw=True) + poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + waterfront:(C(view) + C(condition)\"\n",
        "             \" + poly(yr_built, degree=4, raw=True) + poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + C(view):(C(condition) + poly(yr_built, degree=4, raw=True) + poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + C(condition):(poly(yr_built, degree=4, raw=True) + poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + poly(yr_built, degree=4, raw=True):(poly(yr_renovated, degree=4, raw=True) + C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + poly(yr_renovated, degree=4, raw=True):(C(renovated_flag) + C(basement_flag))\"\n",
        "             \" + C(renovated_flag):C(basement_flag) + C(both)\")"
      ],
      "metadata": {
        "id": "vzCjTTLi6AYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o-Ci21Bp9jA5"
      },
      "source": [
        "# Baseline model including `city`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create variables based on model defined in formula\n",
        "y, X = model_matrix(basecity, data)\n",
        "n, p_city = X.shape\n",
        "\n",
        "logy = data['log_price']\n",
        "\n",
        "# price\n",
        "citylm = perform_cross_validation(LinearRegression(), X, y,\n",
        "                                  scoring=scoring_lev,\n",
        "                                  cvsplit=cvsplit,\n",
        "                                  benchMSE=benchMSE,\n",
        "                                  benchMAE=benchMAE,\n",
        "                                  p=p_city)\n",
        "model_results = update_model_results(model_results, 'City LM', citylm, p_city, p_city)\n",
        "\n",
        "# log-price\n",
        "cityloglm = perform_cross_validation(LinearRegression(), X, logy,\n",
        "                                  scoring=scoring_log,\n",
        "                                  cvsplit=cvsplit,\n",
        "                                  benchMSE=benchMSE,\n",
        "                                  benchMAE=benchMAE,\n",
        "                                  p=p_city)\n",
        "model_results = update_model_results(model_results, 'City logLM', cityloglm, p_city, p_city)"
      ],
      "metadata": {
        "id": "okX3wewi6ZSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Baseline model including `statezip`"
      ],
      "metadata": {
        "id": "PFYdOCYc7GhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create variables based on model defined in formula\n",
        "y, X = model_matrix(basezip, data)\n",
        "n, p_zip = X.shape\n",
        "\n",
        "logy = data['log_price']\n",
        "\n",
        "# price\n",
        "ziplm = perform_cross_validation(LinearRegression(), X, y,\n",
        "                                  scoring=scoring_lev,\n",
        "                                  cvsplit=cvsplit,\n",
        "                                  benchMSE=benchMSE,\n",
        "                                  benchMAE=benchMAE,\n",
        "                                  p=p_zip)\n",
        "model_results = update_model_results(model_results, 'Zip LM', ziplm, p_zip, p_zip)\n",
        "\n",
        "# log-price\n",
        "ziploglm = perform_cross_validation(LinearRegression(), X, logy,\n",
        "                                  scoring=scoring_log,\n",
        "                                  cvsplit=cvsplit,\n",
        "                                  benchMSE=benchMSE,\n",
        "                                  benchMAE=benchMAE,\n",
        "                                  p=p_zip)\n",
        "model_results = update_model_results(model_results, 'Zip logLM', ziploglm, p_zip, p_zip)"
      ],
      "metadata": {
        "id": "8jLKBNXh7L6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G5CenqD-9qhz"
      },
      "source": [
        "# Baseline model including full interaction of `city` and `statezip`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create variables based on model defined in formula\n",
        "y, X = model_matrix(baseboth, data)\n",
        "n, p_both = X.shape\n",
        "\n",
        "logy = data['log_price']\n",
        "\n",
        "# price\n",
        "bothlm = perform_cross_validation(LinearRegression(), X, y,\n",
        "                                  scoring=scoring_lev,\n",
        "                                  cvsplit=cvsplit,\n",
        "                                  benchMSE=benchMSE,\n",
        "                                  benchMAE=benchMAE,\n",
        "                                  p=p_both)\n",
        "model_results = update_model_results(model_results, 'Both LM', bothlm, p_both, p_both)\n",
        "\n",
        "# log-price\n",
        "bothloglm = perform_cross_validation(LinearRegression(), X, logy,\n",
        "                                  scoring=scoring_log,\n",
        "                                  cvsplit=cvsplit,\n",
        "                                  benchMSE=benchMSE,\n",
        "                                  benchMAE=benchMAE,\n",
        "                                  p=p_both)\n",
        "model_results = update_model_results(model_results, 'Both logLM', bothloglm, p_both, p_both)"
      ],
      "metadata": {
        "id": "KX7NAlhB7fvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpKKKwZlUPCf"
      },
      "source": [
        "The categorical variables, particulary `statezip`, seems to be adding a lot of predictive power. **Remember: What information are these categorical variables likely capturing?**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_C0o6_CuUzE3"
      },
      "source": [
        "# Lasso and trees with categorical variables\n",
        "\n",
        "Rather than go through the full collection of models again. Let's just look at how adding these categorical variables affects a couple of the Lasso results and the trees."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4qVAMwjIW2rh"
      },
      "source": [
        "## Lasso with baseline variables and statezip dummies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lasso in the model with statezip\n",
        "\n",
        "# Price model\n",
        "# Create variables from our basezip model\n",
        "y, X = model_matrix(basezip, data)\n",
        "n, p_zip = X.shape\n",
        "\n",
        "# Sequence of penalty parameters to try\n",
        "ub = np.std(y)*np.sqrt(2*np.log(2*p_zip/.05))/np.sqrt(n)\n",
        "lambdas = np.geomspace(start=ub/100, stop=ub, num=25)\n",
        "\n",
        "# Let's do cross-validation to choose a value for lambda\n",
        "model = make_pipeline(StandardScaler(), Lasso())\n",
        "\n",
        "# Cross validation. Set up parameter we are trying to optimize.\n",
        "parameters = {'lasso__alpha':lambdas.ravel()}\n",
        "\n",
        "ziplas = perform_gridsearchcv(model, parameters, scoring=scoring_lev,\n",
        "                               X=X, y=y, cvsplit=cvsplit, refit_metric='mse')\n",
        "\n",
        "ziplasmse, ziplasmae, ziplasp = extract_performance_metrics(ziplas, benchMSE, benchMAE, p_zip)\n",
        "\n",
        "model_results = add_to_results_table(model_results, 'Zip Lasso', ziplasmse, ziplasmae, benchMSE, benchMAE, p_zip, ziplasp)\n",
        "\n",
        "plot_performance(ziplas, title='Zipcode Lasso CV')"
      ],
      "metadata": {
        "id": "adWvLjqTGXf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# log_price model\n",
        "logy = data['log_price']\n",
        "\n",
        "# Sequence of penalty parameters to try\n",
        "ub = np.std(logy)*np.sqrt(2*np.log(2*p_zip/.05))/np.sqrt(n)\n",
        "lambdas = np.geomspace(start=ub/100, stop=ub, num=25)\n",
        "\n",
        "# Cross validation. Set up parameter we are trying to optimize.\n",
        "parameters = {'lasso__alpha':lambdas.ravel()}\n",
        "\n",
        "ziploglas = perform_gridsearchcv(model, parameters, scoring=scoring_log,\n",
        "                               X=X, y=logy, cvsplit=cvsplit, refit_metric='mse')\n",
        "\n",
        "ziploglasmse, ziploglasmae, ziploglasp = extract_performance_metrics(ziploglas, benchMSE, benchMAE, p_zip)\n",
        "\n",
        "model_results = add_to_results_table(model_results, 'Zip logLasso', ziploglasmse, ziploglasmae, benchMSE, benchMAE, p_zip, ziploglasp)\n",
        "\n",
        "plot_performance(ziploglas, title='Zipcode logLasso CV')\n"
      ],
      "metadata": {
        "id": "txbzXcI0HDil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDde5wVjXUG_"
      },
      "source": [
        "## Lasso with baseline variables and statezip x city dummies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lasso in the model with statezip x city\n",
        "\n",
        "# Price model\n",
        "# Create variables from our baseboth model\n",
        "y, X = model_matrix(baseboth, data)\n",
        "n, p_both = X.shape\n",
        "\n",
        "# Sequence of penalty parameters to try\n",
        "ub = np.std(y)*np.sqrt(2*np.log(2*p_both/.05))/np.sqrt(n)\n",
        "lambdas = np.geomspace(start=ub/100, stop=ub, num=25)\n",
        "\n",
        "# Let's do cross-validation to choose a value for lambda\n",
        "model = make_pipeline(StandardScaler(), Lasso())\n",
        "\n",
        "# Cross validation. Set up parameter we are trying to optimize.\n",
        "parameters = {'lasso__alpha':lambdas.ravel()}\n",
        "\n",
        "bothlas = perform_gridsearchcv(model, parameters, scoring=scoring_lev,\n",
        "                               X=X, y=y, cvsplit=cvsplit, refit_metric='mse')\n",
        "\n",
        "bothlasmse, bothlasmae, bothlasp = extract_performance_metrics(bothlas, benchMSE, benchMAE, p_both)\n",
        "\n",
        "model_results = add_to_results_table(model_results, 'Both Lasso', bothlasmse, bothlasmae, benchMSE, benchMAE, p_both, bothlasp)\n",
        "\n",
        "plot_performance(bothlas, title='Both Lasso CV')"
      ],
      "metadata": {
        "id": "mDUSmJw9T6Ie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# log_price model\n",
        "logy = data['log_price']\n",
        "\n",
        "# Sequence of penalty parameters to try\n",
        "ub = np.std(logy)*np.sqrt(2*np.log(2*p_both/.05))/np.sqrt(n)\n",
        "lambdas = np.geomspace(start=ub/100, stop=ub, num=25)\n",
        "\n",
        "# Cross validation. Set up parameter we are trying to optimize.\n",
        "parameters = {'lasso__alpha':lambdas.ravel()}\n",
        "\n",
        "bothloglas = perform_gridsearchcv(model, parameters, scoring=scoring_log,\n",
        "                               X=X, y=logy, cvsplit=cvsplit, refit_metric='mse')\n",
        "\n",
        "bothloglasmse, bothloglasmae, bothloglasp = extract_performance_metrics(bothloglas, benchMSE, benchMAE, p_both)\n",
        "\n",
        "model_results = add_to_results_table(model_results, 'Both logLasso',\n",
        "                                     bothloglasmse, bothloglasmae,\n",
        "                                     benchMSE, benchMAE, p_both, bothloglasp)\n",
        "\n",
        "plot_performance(bothloglas, title='Both logLasso CV')\n"
      ],
      "metadata": {
        "id": "Gx5Zzu49UVOU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37w16tesaxHd"
      },
      "source": [
        "## Lasso with flexible variables and statezip x city dummies\n",
        "\n",
        "For giggles, let's look at what happens when we take the \"flexible\" model and throw in the `statezip` x `city` dummies.\n",
        "\n",
        "**This block takes ~10 minutes to run**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lasso in the very flexible model\n",
        "\n",
        "# Price model\n",
        "# Create variables from our flex2 model\n",
        "y, X = model_matrix(flex2, data)\n",
        "n, p_flex2 = X.shape\n",
        "\n",
        "# Sequence of penalty parameters to try\n",
        "ub = np.std(y)*np.sqrt(2*np.log(2*p_flex2/.05))/np.sqrt(n)\n",
        "lambdas = np.geomspace(start=ub/100, stop=ub, num=25)\n",
        "\n",
        "# Let's do cross-validation to choose a value for lambda\n",
        "model = make_pipeline(StandardScaler(), Lasso())\n",
        "\n",
        "# Cross validation. Set up parameter we are trying to optimize.\n",
        "parameters = {'lasso__alpha':lambdas.ravel()}\n",
        "\n",
        "flex2las = perform_gridsearchcv(model, parameters, scoring=scoring_lev,\n",
        "                               X=X, y=y, cvsplit=cvsplit, refit_metric='mse')\n",
        "\n",
        "flex2lasmse, flex2lasmae, flex2lasp = extract_performance_metrics(flex2las, benchMSE, benchMAE, p_flex2)\n",
        "\n",
        "model_results = add_to_results_table(model_results, 'Very Flexible Lasso', flex2lasmse, flex2lasmae, benchMSE, benchMAE, p_flex2, flex2lasp)\n",
        "\n",
        "plot_performance(flex2las, title='Very Flexible Lasso CV')"
      ],
      "metadata": {
        "id": "RkMAI1P3Uruu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# log_price model\n",
        "# Create variables from our flex2 model\n",
        "logy = data['log_price']\n",
        "\n",
        "# Sequence of penalty parameters to try\n",
        "ub = np.std(logy)*np.sqrt(2*np.log(2*p_flex2/.05))/np.sqrt(n)\n",
        "lambdas = np.geomspace(start=ub/100, stop=ub, num=25)\n",
        "\n",
        "# Let's do cross-validation to choose a value for lambda\n",
        "model = make_pipeline(StandardScaler(), Lasso())\n",
        "\n",
        "# Cross validation. Set up parameter we are trying to optimize.\n",
        "parameters = {'lasso__alpha':lambdas.ravel()}\n",
        "\n",
        "flex2loglas = perform_gridsearchcv(model, parameters, scoring=scoring_log,\n",
        "                               X=X, y=logy, cvsplit=cvsplit, refit_metric='mse')\n",
        "\n",
        "flex2loglasmse, flex2loglasmae, flex2loglasp = extract_performance_metrics(flex2loglas, benchMSE, benchMAE, p_flex2)\n",
        "\n",
        "model_results = add_to_results_table(model_results, 'Very Flexible logLasso', flex2loglasmse, flex2loglasmae, benchMSE, benchMAE, p_flex2, flex2loglasp)\n",
        "\n",
        "plot_performance(flex2loglas, title='Very Flexible logLasso CV')"
      ],
      "metadata": {
        "id": "UU1vB0M7Vwwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DumRTotOkn3e"
      },
      "source": [
        "# Tree with `statezip` and `city`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vvvy8Fe8ktxi"
      },
      "source": [
        "For use with trees, we are going to need to create dummy variables for `statezip` and `city`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_4us7XKtkseW"
      },
      "outputs": [],
      "source": [
        "data_tree = data.drop(columns=['renovated_flag','basement_flag'])\n",
        "data_tree = pd.get_dummies(data_tree, columns=['statezip','city'])\n",
        "\n",
        "# Let's make our outcome variables and predictors\n",
        "X = data_tree.drop(columns=['price','log_price','both'])\n",
        "y = data_tree['price']\n",
        "logy = data_tree['log_price']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h22OQPdalB8g"
      },
      "source": [
        "Let's look at a baseline tree for `price`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Outcome variable is price\n",
        "# Parameter we want to choose based on cross-validation performance - number of leaves\n",
        "parameters = {'max_leaf_nodes':range(2,101)}\n",
        "\n",
        "# Define model and do cross-validation\n",
        "tree = DecisionTreeRegressor()\n",
        "both_tree = perform_gridsearchcv(tree, parameters, scoring=scoring_lev,\n",
        "                                 X=X, y=y, cvsplit=cvsplit, refit_metric='mse')\n",
        "\n",
        "bestmse_both_tree, bestmae_both_tree, both_tree_p = extract_tree_metrics(both_tree, benchMSE, benchMAE)\n",
        "\n",
        "plot_tree_performance(both_tree)\n",
        "\n",
        "model_results = add_to_results_table(model_results, 'Decision Tree w Dummies',\n",
        "                                     bestmse_both_tree, bestmae_both_tree,\n",
        "                                     benchMSE, benchMAE, '-', both_tree_p)\n",
        "\n"
      ],
      "metadata": {
        "id": "Wse5IV1zWw-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Baseline tree for `log_price`"
      ],
      "metadata": {
        "id": "YbAlaNlkW1z2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Outcome variable is log_price\n",
        "# Parameter we want to choose based on cross-validation performance - number of leaves\n",
        "parameters = {'max_leaf_nodes':range(2,101)}\n",
        "\n",
        "# Define model and do cross-validation\n",
        "tree = DecisionTreeRegressor()\n",
        "both_logtree = perform_gridsearchcv(tree, parameters, scoring=scoring_log,\n",
        "                                 X=X, y=logy, cvsplit=cvsplit, refit_metric='mse')\n",
        "\n",
        "bestmse_both_logtree, bestmae_both_logtree, both_logtree_p = extract_tree_metrics(both_logtree, benchMSE, benchMAE)\n",
        "\n",
        "plot_tree_performance(both_logtree)\n",
        "\n",
        "model_results = add_to_results_table(model_results, 'Decision Tree w Dummies - Log',\n",
        "                                     bestmse_both_logtree, bestmae_both_logtree,\n",
        "                                     benchMSE, benchMAE, '-', both_logtree_p)\n",
        "\n"
      ],
      "metadata": {
        "id": "yE98h7RzW4V0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at all the results again."
      ],
      "metadata": {
        "id": "7vw7CKtPYE8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_results.sort_values(by=['RMSE'])"
      ],
      "metadata": {
        "id": "1vUuBvrVYHfY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Summary\n",
        "\n",
        "Linear models are very useful and tend to do well with structured, numeric data in relatively small samples. In many settings, sensible linear models should be in the set of learners considered. Linear models also come with a lot of overhead and choice on the side of the analyst that makes them cumbersome and unappealing in more complex settings.\n",
        "\n",
        "Trees offer a simple approach to modeling with representation learning. They are fast and flexible. Simple trees (relatively few terminal nodes) are also highly interpretable and intuitive. Basic trees are also crude in that they provide step function approximations. They are a building block to other learners though and a solid baseline procedure."
      ],
      "metadata": {
        "id": "Opv6vRgLn6Zl"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}