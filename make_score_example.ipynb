{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2t30yFTMOSWBxXq7ZcUAI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fengfrankgthb/BUS-41204/blob/main/make_score_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example make_score()"
      ],
      "metadata": {
        "id": "dTUjmvc1V0Pl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWhymJ6AVtG6",
        "outputId": "a0bff28b-1bc8-49d5-ac62-42973f78476a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Raw scores returned by cross_val_score: [-1.94365063 -0.87579212 -0.5       ]\n",
            "Mean cross-validation RMSE: 1.106480916608513\n",
            "\n",
            "--- Explanation ---\n",
            "The 'cross_val_score' function used our 'rmse_scorer' to evaluate the LinearRegression model across 3 cross-validation folds.\n",
            "For each fold, the model was trained on a subset of the data and evaluated on the remaining part.\n",
            "The 'rmse_scorer' called our 'custom_rmse' function, which calculated the RMSE and returned its negative.\n",
            "Therefore, the 'scores' array contains the negative RMSE values for each fold.\n",
            "To get the actual RMSE values, we negate the scores.\n",
            "A lower positive RMSE indicates better model performance.\n",
            "\n",
            "--- Another Example with a Different Metric ---\n",
            "Raw R-squared scores: [-2.77777778 -2.06804734         nan]\n",
            "Mean cross-validation R-squared: nan\n",
            "Here, higher R-squared values indicate better fit, and 'greater_is_better' was the default.\n",
            "\n",
            "--- Example with a Scoring Function Where Lower is Better ---\n",
            "Raw MAE scores (lower is better): [-1.66666667 -0.82692308 -0.5       ]\n",
            "Mean cross-validation MAE: -0.9978632478632479\n",
            "Here, 'greater_is_better=False' tells scikit-learn that lower scores from 'custom_mae' are better.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_regression.py:1266: UndefinedMetricWarning: R^2 score is not well-defined with less than two samples.\n",
            "  warnings.warn(msg, UndefinedMetricWarning)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import make_scorer, mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# 1. Define a custom scoring function\n",
        "def custom_rmse(y_true, y_pred):\n",
        "    \"\"\"Custom Root Mean Squared Error (RMSE) function.\"\"\"\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    return -rmse  # Return negative RMSE so higher is better for make_scorer\n",
        "\n",
        "# 2. Create a scorer object using make_scorer\n",
        "rmse_scorer = make_scorer(custom_rmse, greater_is_better=True)\n",
        "\n",
        "# 3. Prepare some sample data\n",
        "X = np.array([[1], [2], [3], [4], [5]])\n",
        "y = np.array([2, 4, 5, 4, 5])\n",
        "\n",
        "# 4. Train a simple model\n",
        "model = LinearRegression()\n",
        "\n",
        "# 5. Use the custom scorer in cross_val_score\n",
        "scores = cross_val_score(model, X, y, cv=3, scoring=rmse_scorer)\n",
        "\n",
        "# 6. Examine the results\n",
        "\n",
        "print(\"Raw scores returned by cross_val_score:\", scores)\n",
        "print(\"Mean cross-validation RMSE:\", -np.mean(scores)) # Invert back to positive RMSE\n",
        "\n",
        "print(\"\\n--- Explanation ---\")\n",
        "print(\"The 'cross_val_score' function used our 'rmse_scorer' to evaluate the LinearRegression model across 3 cross-validation folds.\")\n",
        "print(\"For each fold, the model was trained on a subset of the data and evaluated on the remaining part.\")\n",
        "print(\"The 'rmse_scorer' called our 'custom_rmse' function, which calculated the RMSE and returned its negative.\")\n",
        "print(\"Therefore, the 'scores' array contains the negative RMSE values for each fold.\")\n",
        "print(\"To get the actual RMSE values, we negate the scores.\")\n",
        "print(\"A lower positive RMSE indicates better model performance.\")\n",
        "\n",
        "print(\"\\n--- Another Example with a Different Metric ---\")\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# 1. Define a custom R-squared scorer (greater_is_better is True by default)\n",
        "r2_scorer = make_scorer(r2_score)\n",
        "\n",
        "# 2. Use the custom scorer in cross_val_score\n",
        "r2_scores = cross_val_score(model, X, y, cv=3, scoring=r2_scorer)\n",
        "\n",
        "print(\"Raw R-squared scores:\", r2_scores)\n",
        "print(\"Mean cross-validation R-squared:\", np.mean(r2_scores))\n",
        "print(\"Here, higher R-squared values indicate better fit, and 'greater_is_better' was the default.\")\n",
        "\n",
        "print(\"\\n--- Example with a Scoring Function Where Lower is Better ---\")\n",
        "\n",
        "def custom_mae(y_true, y_pred):\n",
        "    \"\"\"Custom Mean Absolute Error (MAE) function.\"\"\"\n",
        "    mae = np.mean(np.abs(y_true - y_pred))\n",
        "    return mae  # Return positive MAE, but we'll tell make_scorer lower is better\n",
        "\n",
        "# 1. Create a scorer object specifying greater_is_better=False\n",
        "mae_scorer = make_scorer(custom_mae, greater_is_better=False)\n",
        "\n",
        "# 2. Use the custom scorer in cross_val_score\n",
        "mae_scores = cross_val_score(model, X, y, cv=3, scoring=mae_scorer)\n",
        "\n",
        "print(\"Raw MAE scores (lower is better):\", mae_scores)\n",
        "print(\"Mean cross-validation MAE:\", np.mean(mae_scores))\n",
        "print(\"Here, 'greater_is_better=False' tells scikit-learn that lower scores from 'custom_mae' are better.\")"
      ]
    }
  ]
}