{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fengfrankgthb/BUS-41204/blob/main/StudentSearchingWorkflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Workflow - Find My Students"
      ],
      "metadata": {
        "id": "LBXDt8KTnWgW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will illustrate a workflow that makes use of an LLM and web search tool to try to locate LinkedIn profiles of my past students."
      ],
      "metadata": {
        "id": "ZTYhYyr8ndB3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Mount Google Drive"
      ],
      "metadata": {
        "id": "FfqjKJXZnr4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'd like to access information on my google drive where I have stored API (Application Programming Interface) keys needed to call OpenAI and the search tool and a spreadsheet with the names of my previous students. I'm also going to store the results back to my google drive when I'm done."
      ],
      "metadata": {
        "id": "Xgkk-9L0nvLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True) # force_remount = True"
      ],
      "metadata": {
        "id": "ktjUgM1iI5-Y",
        "outputId": "46b54a16-cf30-415a-fd51-88648b847d6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API keys"
      ],
      "metadata": {
        "id": "0IEQyix1oMoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To make use of calls to services, we will need keys to access them. I want to keep my keys private and at least moderately safe by not displaying them directly in the notebook.\n",
        "\n",
        "If someone other than me wanted to run this notebook, they would need to have their own API keys and then adapt the code block below to use them."
      ],
      "metadata": {
        "id": "jLXhQEO2oQDw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azkncGBoHGWD"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# You would need to have your own API keys stored in your own google drive\n",
        "# to execute this script yourself\n",
        "# Load API keys\n",
        "with open('/content/drive/My Drive/ColabSecrets/secrets.json', 'r') as f:\n",
        "    secrets = json.load(f)\n",
        "\n",
        "OPENAI_API_KEY = secrets[\"OPENAI_API_KEY\"]\n",
        "VALUE_SERP_API_KEY = secrets[\"VALUE_SERP_API_KEY\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Add libraries"
      ],
      "metadata": {
        "id": "wN74uDEKorWb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to make use of OpenAI as our LLM."
      ],
      "metadata": {
        "id": "RLW9TiZqotxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain_openai"
      ],
      "metadata": {
        "id": "xarBrAf2uPE0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from langchain_openai import ChatOpenAI"
      ],
      "metadata": {
        "id": "7z1TGAZcO5gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tools and LLM queries"
      ],
      "metadata": {
        "id": "9NAbsA42o189"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the following several code blocks, we're going to define a series of tools and functions to make LLM queries. These are going to be the main building blocks of our workflow."
      ],
      "metadata": {
        "id": "sKiIQ8CEo8CZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`get_synonyms` will make use of the LLM to generate additional terms to use in our web searches."
      ],
      "metadata": {
        "id": "2cINx7CCpHqh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_synonyms(term):\n",
        "    \"\"\"Uses an LLM to generate synonyms for a given search term.\"\"\"\n",
        "    llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Given the term: \"{term}\",\n",
        "    generate a list of common synonyms or alternative names that should be included in a web search.\n",
        "    Respond with a short, comma-separated list of synonyms.\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    return response.content.split(\", \")\n"
      ],
      "metadata": {
        "id": "S_OWGALv6MJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`search_linkedin` makes use of a websearch tool to conduct the initial search trying to find linkedin profiles for individuals identified by name, a year they were in school, and the school they went to. Additional terms may also be provided."
      ],
      "metadata": {
        "id": "489lZeGxpjj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_linkedin(student_name, year_taught, school, additional_terms=\"\", start_index=0):\n",
        "    \"\"\"Searches for LinkedIn profiles, expanding search terms with synonyms.\"\"\"\n",
        "\n",
        "    # Generate year range\n",
        "    years = f\"{year_taught} OR {int(year_taught) + 1} OR {int(year_taught) + 2} OR {int(year_taught) + 3}\"\n",
        "\n",
        "    # **Expand school name with synonyms**\n",
        "    school_synonyms = get_synonyms(school)\n",
        "    expanded_school_terms = \" OR \".join([school] + school_synonyms)\n",
        "\n",
        "    # Construct search query\n",
        "    query = f'{student_name} linkedin ({expanded_school_terms}) ({years}) {additional_terms}'\n",
        "    # print(f\"Query: {query}\")\n",
        "\n",
        "    url = \"https://api.valueserp.com/search\"\n",
        "\n",
        "    params = {\n",
        "        \"api_key\": VALUE_SERP_API_KEY,\n",
        "        \"q\": query,\n",
        "        \"location\": \"United States\",\n",
        "        \"hl\": \"en\",\n",
        "        \"gl\": \"us\",\n",
        "        \"num\": 10,\n",
        "        \"start\": start_index,\n",
        "        \"no_truncate\": \"true\"\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "    if response.status_code != 200:\n",
        "        print(\"Error fetching search results.\")\n",
        "        return []\n",
        "\n",
        "    results = response.json().get(\"organic_results\", [])\n",
        "\n",
        "    # **Filter to include only LinkedIn URLs**\n",
        "    linkedin_results = [\n",
        "        {\"title\": r.get(\"title\", \"\"),\n",
        "         \"link\": r.get(\"link\", \"\"),\n",
        "         \"snippet\": r.get(\"snippet\", \"\")}\n",
        "        for r in results\n",
        "        if \"linkedin.com/in/\" in r.get(\"link\", \"\")\n",
        "    ]\n",
        "\n",
        "    return linkedin_results"
      ],
      "metadata": {
        "id": "4jzwNNy3PkD5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`extract_relevant_info` parses search results."
      ],
      "metadata": {
        "id": "RZYiStBGp3BT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_relevant_info(student, year, school, search_results, program=\"\"):\n",
        "    \"\"\"Processes search results to estimate likelihood of match.\"\"\"\n",
        "    profiles = []\n",
        "    for result in search_results:\n",
        "        title = result.get(\"title\", \"\")\n",
        "        snippet = result.get(\"snippet\", \"\")\n",
        "        link = result.get(\"link\", \"\")\n",
        "        likelihood = estimate_match_likelihood(student, year, school, title, snippet, program)\n",
        "        profiles.append((title, link, snippet, likelihood))\n",
        "    return profiles\n"
      ],
      "metadata": {
        "id": "Yt2Qt7tUSJrq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`estimate_match_likelihood` makes use of the LLM to assess returned prompts for how likely they are to correspond to the desired student. Because the only information available is the returned search result (url, snippet, and headline), the evaluation is not incredibly accurate. However, I do not want to scrape (too much) data directly from websites without checking policies."
      ],
      "metadata": {
        "id": "Nx7ewzKOp7bc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def estimate_match_likelihood(student, year, school, title, snippet, program):\n",
        "    \"\"\"Uses LLM to estimate likelihood that snippet belongs to student.\"\"\"\n",
        "\n",
        "    llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Given the following search result title and snippet:\n",
        "\n",
        "    - **Title:** \"{title}\"\n",
        "    - **Snippet:** \"{snippet}\"\n",
        "\n",
        "    Estimate the likelihood (0-1) that this is the correct LinkedIn profile of the student named \"{student}\".\n",
        "\n",
        "    ### **Guidelines for Likelihood Estimation**\n",
        "\n",
        "    The student name provided will generally be in the form of FIRST NAME LAST NAME\n",
        "    or (FIRST NAME OR NICKNAME) LAST NAME.\n",
        "\n",
        "    The first two words of Title will often be FIRST NAME LAST NAME, and Title\n",
        "    will almost always include a proper name with first and last name.\n",
        "\n",
        "    Before comparing names, try to extrac FIRST NAME and LAST NAME from the title and store them in memory.\n",
        "    Name comparisons should be made character by character.\n",
        "\n",
        "    1. **First Name Matching:**\n",
        "      - If the first name in the title exactly matches or is a common variation of the student's name, this increases confidence.\n",
        "      - If the first name is different but phonetically or culturally similar, reduce the score slightly.\n",
        "      - If the first name is completely different, penalize significantly.\n",
        "\n",
        "    2. **Last Name Matching:**\n",
        "      - If the last name in the title matches exactly, this is a strong signal.\n",
        "      - If the last name is slightly different but could be a common variation, reduce confidence slightly.\n",
        "      - If the last name is completely different, penalize significantly.\n",
        "\n",
        "    3.  **First and Last Name Matching**\n",
        "      - If both first and last name match exactly, this is a strong signal.\n",
        "\n",
        "    4. **Education & School Match:**\n",
        "      - If the snippet confirms the student attended \"{school}\", this increases confidence.\n",
        "      - If school is missing or education is not provided, this should not increase or decrease confidence.\n",
        "\n",
        "    5. **Program Match:**\n",
        "      - If the snippet confirms the student was in the \"{program}\" program, this increases confidence.\n",
        "      - If the program is clear but different, reduce confidence significantly.\n",
        "      - If the program is missing, this should not increase or decrease confidence.\n",
        "\n",
        "    6. **Employment & Experience:**\n",
        "      - If the snippet contains employment information but no education details, rely mostly on name matching.\n",
        "      - If the experience or employment information strongly aligns with what would be expected for a \"{program}\"\n",
        "        student from \"{school}\", increase the score slightly. For example, if employment or title indicates\n",
        "        the person is employed at a university and the person's program is PhD, this increases confidence\n",
        "        in the match.\n",
        "\n",
        "    ### **Final Output (Force Consistency)**\n",
        "    1. First, output the extracted first and last names **in a structured format**.\n",
        "    2. Then, compute the likelihood **based on the reasoning steps above** and return it.\n",
        "    3. **ALWAYS use the same process for reasoning, even if not explicitly asked.**\n",
        "\n",
        "    ### **Final Structured Output (Do Not Deviate)**\n",
        "    Respond in the following exact format:\n",
        "\n",
        "    Reasoning: First Name Match: [Exact/Close/No Match]\n",
        "               Last Name Match: [Exact/Close/No Match]\n",
        "               School Match: [Match/No Match]\n",
        "               Program Match: [Match/Not Mentioned/Different]\n",
        "               Employment Match: [Relevant/Not Relevant]\n",
        "\n",
        "    Final Likelihood: [0-1]\n",
        "\n",
        "    Make sure the likelihood value is **always on the last line, prefixed exactly with \"Final Likelihood: \" for easy extraction.**\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "\n",
        "    try:\n",
        "        return float(response.content.split(\"Final Likelihood: \")[-1])\n",
        "    except ValueError:\n",
        "        return 0.5  # Default uncertainty"
      ],
      "metadata": {
        "id": "uNMa4izqSNHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`suggest_refinement_terms` uses the LLM to process a results that is believed to match a student and generate additional search terms for use in further search trying to decide whether the student is in the analytics space."
      ],
      "metadata": {
        "id": "lV9soGd5qdLH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def suggest_refinement_terms(title, snippet):\n",
        "    \"\"\"Uses an LLM to generate the best search terms based on the title and snippet associated with a linked in url returned from a web search.\"\"\"\n",
        "\n",
        "    llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    The following title and snippet are associated with a linked in url returned from a web search:\n",
        "\n",
        "    title:\n",
        "\n",
        "    \"{title}\"\n",
        "\n",
        "    snippet:\n",
        "\n",
        "    \"{snippet}\"\n",
        "\n",
        "    Suggest the best set of search terms to use in a general web search to determine whether the person associated with the LinkedIn account is involved in AI/ML.\n",
        "    Prioritize any company names, job roles, and technical keywords in the title or snippet.\n",
        "\n",
        "    Respond with a comma-separated list of refined search terms.\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    return response.content.split(\", \")\n"
      ],
      "metadata": {
        "id": "PrzgjbUBU4F2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`search_general_web` just conducts a web search given a set of words. (Really don't need `search_general_web` and `search_linked_in`, but my chain of thought just went this way.)"
      ],
      "metadata": {
        "id": "zUcXPsGyqtYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def search_general_web(person_name, additional_terms=\"\"):\n",
        "    \"\"\"Conducts a general web search using the person's name and relevant terms.\"\"\"\n",
        "\n",
        "    query = f'{person_name} {additional_terms}'\n",
        "\n",
        "    url = \"https://api.valueserp.com/search\"\n",
        "\n",
        "    params = {\n",
        "        \"api_key\": VALUE_SERP_API_KEY,\n",
        "        \"q\": query,\n",
        "        \"location\": \"United States\",\n",
        "        \"hl\": \"en\",\n",
        "        \"gl\": \"us\",\n",
        "        \"num\": 10  # Retrieve 10 results at a time\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, params=params)\n",
        "    if response.status_code != 200:\n",
        "        print(\"Error fetching search results.\")\n",
        "        return []\n",
        "\n",
        "    results = response.json().get(\"organic_results\", [])\n",
        "\n",
        "    # Return both the link and snippet for further AI/ML assessment\n",
        "    return [{\"link\": r.get(\"link\", \"\"), \"snippet\": r.get(\"snippet\", \"\")}\n",
        "            for r in results]\n"
      ],
      "metadata": {
        "id": "kYASGbwl71bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`assess_ai_ml_likelihood` uses a full set of returned web results (that include a person's name) from a search to try to decide whether it seems likely that the person is in the analytics space."
      ],
      "metadata": {
        "id": "PqsynAnWq_UI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assess_ai_ml_likelihood(web_results):\n",
        "    \"\"\"Uses an LLM to determine the likelihood that the person works in AI/ML based on search results.\"\"\"\n",
        "\n",
        "    llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0)\n",
        "\n",
        "    # Combine snippets into a single context\n",
        "    snippets_text = \"\\n\".join([result[\"snippet\"] for result in web_results])\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Given the following search result snippets:\n",
        "\n",
        "    \"{snippets_text}\"\n",
        "\n",
        "    Estimate the likelihood (0-1) that the person mentioned in these results is involved in AI/ML or data analytics.\n",
        "    Consider whether they work at an AI/ML/analytics related firm, are involved in AI/ML/analytics research, or engage in related activities.\n",
        "    Examples of related activities might include research in AI, machine learning, deep learning, or data science; being\n",
        "    in venture capital investing in AI/ML/analytics firms; or being on a board at an AI-related company.\n",
        "    Other examples that should return a value around .6 might be doing research or working in econometrics or statistics\n",
        "    without any explicit results referencing AI/ML.\n",
        "\n",
        "    Respond with a number between 0 and 1, followed by a short explanation.\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    return response\n"
      ],
      "metadata": {
        "id": "egifi5lfCWax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`assess_ai_ml_from_snippet` is as above but only uses the snippet from a url identified as likely belong to a student in the initial search."
      ],
      "metadata": {
        "id": "MV1672WgruXq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def assess_ai_ml_from_snippet(title, snippet):\n",
        "    \"\"\"Uses an LLM to estimate AI/ML involvement based solely on the LinkedIn snippet.\"\"\"\n",
        "\n",
        "    llm = ChatOpenAI(openai_api_key=OPENAI_API_KEY, temperature=0)\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Given the following LinkedIn snippet and title -\n",
        "\n",
        "    title:\n",
        "\n",
        "    \"{title}\"\n",
        "\n",
        "    snippet:\n",
        "\n",
        "    \"{snippet}\"\n",
        "\n",
        "    Estimate the likelihood (0-1) that the person mentioned in these results is involved in AI/ML or data analytics.\n",
        "    Consider whether they work at an AI/ML/analytics related firm, are involved in AI/ML/analytics research, or engage in related activities.\n",
        "    Examples of related activities might include research in AI, machine learning, deep learning, or data science; being\n",
        "    in venture capital investing in AI/ML/analytics firms; or being on a board at an AI-related company.\n",
        "    Other examples that should return a value around .6 might be doing research or working in econometrics or statistics\n",
        "    without any explicit results referencing AI/ML.\n",
        "\n",
        "    Respond with a number between 0 and 1, followed by a short explanation.\n",
        "    \"\"\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    return response\n"
      ],
      "metadata": {
        "id": "_u7Bpww474vQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`save_to_spreadsheet` does just what it says when we're looking at results produced from running the workflow interactively."
      ],
      "metadata": {
        "id": "A-loONQ4sOi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_to_spreadsheet(data, filename=\"student_profiles.xlsx\"):\n",
        "    \"\"\"Saves the search results to an Excel spreadsheet.\"\"\"\n",
        "    df = pd.DataFrame(data, columns=[\n",
        "        \"Student Name\", \"LinkedIn URL\", \"Match Likelihood\", \"AI/ML Likelihood\", \"Summary\"\n",
        "    ])\n",
        "    df.to_excel(filename, index=False)\n",
        "    print(f\"Results saved to {filename}\")\n"
      ],
      "metadata": {
        "id": "CFO9kThWSQvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the workflow"
      ],
      "metadata": {
        "id": "iheZB7xhsXd3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code ties everything together to allow us to interactively run through the workflow. This allows us to see how everything works and gives more flexibility over the inputs."
      ],
      "metadata": {
        "id": "E5wCYuMssZW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Interactive Process\n",
        "data = []\n",
        "\n",
        "while True:\n",
        "    # Step 1: Prompt for student info\n",
        "    student_name = input(\"Enter student name: \")\n",
        "    year_taught = input(\"Enter year taught: \")\n",
        "    school = input(f\"Enter school (default: UChicago): \") or \"University of Chicago\"\n",
        "    program = input(f\"Enter program (default: MBA): \") or \"MBA\"\n",
        "    additional_terms = input(\"Enter additional search terms (or leave blank): \")\n",
        "\n",
        "    start_index = 0  # Track pagination index\n",
        "\n",
        "    while True:\n",
        "        print(f\"Searching for LinkedIn profiles (results {start_index + 1}-{start_index + 10})...\")\n",
        "        search_results = search_linkedin(student_name, year_taught, school, additional_terms, start_index)\n",
        "\n",
        "        if not search_results:\n",
        "            retry = input(\"No profiles found. Provide more search terms? (y/n): \")\n",
        "            if retry.lower() == \"y\":\n",
        "                new_terms = input(\"Enter additional search terms: \").strip()\n",
        "                additional_terms += \" \" + new_terms if new_terms else \"\"\n",
        "                start_index = 0  # Reset pagination\n",
        "                continue  # Re-run search with new terms\n",
        "            else:\n",
        "                data.append([student_name, \"Not found\", \"\", \"\", \"\"])\n",
        "                break\n",
        "\n",
        "        found_match = False  # Track if a match is confirmed\n",
        "\n",
        "        for title, link, snippet, likelihood in extract_relevant_info(student_name, year_taught, school, search_results, program):\n",
        "            print(f\"\\nPossible match:\\nTitle: {title}\\nURL: {link}\\nSnippet: {snippet}\\nLikelihood: {likelihood:.2f}\")\n",
        "            confirm = input(\"Is this the correct profile? (y/n): \")\n",
        "\n",
        "            if confirm.lower() == \"y\":\n",
        "                found_match = True  # Stop further link processing\n",
        "\n",
        "                # Step 3: Initial AI/ML Assessment Using LinkedIn Snippet\n",
        "                print(\"\\nAssessing AI/ML involvement based on LinkedIn snippet...\")\n",
        "                ai_ml_result = assess_ai_ml_from_snippet(title, snippet)\n",
        "                likelihood_ai_ml, summary = ai_ml_result.content.split(\"\\n\", 1)\n",
        "\n",
        "                print(f\"\\nAI/ML Likelihood (Snippet Only): {likelihood_ai_ml}\")\n",
        "                print(f\"Reasoning: {summary}\")\n",
        "\n",
        "                stop_here = input(\"Are you satisfied with this result? (y/n): \")\n",
        "\n",
        "                if stop_here.lower() == \"y\":\n",
        "                    # Save results and break out of search\n",
        "                    data.append([student_name, link, likelihood, likelihood_ai_ml, summary])\n",
        "                    break  # Move to next student immediately\n",
        "\n",
        "                # Step 4: Conduct General Web Search for Further Verification\n",
        "                print(\"\\nConducting a general web search for additional AI/ML verification...\")\n",
        "                refined_search_terms = suggest_refinement_terms(title, snippet)\n",
        "\n",
        "                print(f\"\\nSearch terms for additional AI/ML assessment: {', '.join(refined_search_terms)}\")\n",
        "\n",
        "                user_additional_terms = input(\"Enter any additional words to include (or press enter to skip): \").strip()\n",
        "                if user_additional_terms:\n",
        "                    refined_search_terms.append(user_additional_terms)\n",
        "\n",
        "                print(\"\\nConducting a general web search for additional AI/ML verification...\")\n",
        "                general_search_results = search_general_web(student_name, \" \".join(refined_search_terms))\n",
        "\n",
        "                # Step 5: Final AI/ML Assessment Based on Web Search\n",
        "                if general_search_results:\n",
        "                    ai_ml_result = assess_ai_ml_likelihood(general_search_results)\n",
        "                    likelihood_ai_ml, summary = ai_ml_result.content.split(\"\\n\", 1)\n",
        "\n",
        "                    print(f\"\\nFinal AI/ML Likelihood (Web Search): {likelihood_ai_ml}\")\n",
        "                    print(f\"Reasoning: {summary}\")\n",
        "\n",
        "                # Save final results and **stop searching**\n",
        "                data.append([student_name, link, likelihood, likelihood_ai_ml, summary])\n",
        "                break  # Move to next student immediately\n",
        "\n",
        "        if found_match:\n",
        "            break  # **Ensure no more LinkedIn results are checked once a match is found**\n",
        "\n",
        "        # If no match was found after checking all results, allow refinement\n",
        "        more_results = input(\"No profiles matched. Search for more results with the same terms? (y/n): \")\n",
        "        if more_results.lower() == \"y\":\n",
        "            start_index += 10  # Fetch next set of results\n",
        "            continue  # Re-run search without changing search terms\n",
        "\n",
        "        retry = input(\"Provide new search terms? (y/n): \")\n",
        "        if retry.lower() == \"y\":\n",
        "            new_terms = input(\"Enter additional search terms: \").strip()\n",
        "            additional_terms += \" \" + new_terms if new_terms else \"\"\n",
        "            start_index = 0  # Reset pagination\n",
        "            continue  # Re-run search with additional details\n",
        "        else:\n",
        "            data.append([student_name, \"Not found\", \"\", \"\", \"\"])\n",
        "            break\n",
        "\n",
        "    another = input(\"Search for another student? (y/n): \")\n",
        "    if another.lower() != \"y\":\n",
        "        break"
      ],
      "metadata": {
        "id": "K3pSR40ZO3yo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save results only after all refinements\n",
        "save_to_spreadsheet(data)"
      ],
      "metadata": {
        "id": "zCwmprlntw_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Automate the workflow"
      ],
      "metadata": {
        "id": "4HemDIYHskGc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we automate the workflow to take as input a spreadsheet containing names and year taught and output the spreadsheet updated with the results of executing the workflow student by student."
      ],
      "metadata": {
        "id": "wrpjXMC6sn_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Automate the process\n",
        "\n",
        "def process_students(file_path, out_file_path=\"student_profiles.xlsx\", row_indices=None):\n",
        "    # Load the spreadsheet\n",
        "    df = pd.read_excel(file_path)\n",
        "\n",
        "    if row_indices is not None:\n",
        "        df = df.iloc[row_indices]\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        last_name, first_name = row['Name'].split(', ')\n",
        "        preferred_name = row['Preferred Name']\n",
        "        student_name = f\"({first_name} OR {preferred_name}) {last_name}\"\n",
        "        year_taught = row['Year']\n",
        "        program = row['Program']\n",
        "        school = 'University of Chicago'\n",
        "        additional_terms = ''\n",
        "        if year_taught > 2007:\n",
        "            additional_terms += 'Booth '\n",
        "            school += ' Booth School of Business'\n",
        "        if 'PhD' in program:\n",
        "            additional_terms += 'PhD '\n",
        "        if 'MBA' in program:\n",
        "            additional_terms += 'MBA '\n",
        "\n",
        "        start_index = 0  # Track pagination index\n",
        "        best_match = None  # Track the best LinkedIn match\n",
        "        best_likelihood = 0  # Highest found likelihood\n",
        "\n",
        "        while True:\n",
        "            print(f\"Searching for LinkedIn profile for {student_name} ...\")\n",
        "            search_results = search_linkedin(student_name, year_taught, school, additional_terms, start_index)\n",
        "            if not search_results:\n",
        "                break  # Stop searching if no results are found\n",
        "\n",
        "            for title, link, snippet, likelihood in extract_relevant_info(student_name, year_taught, school, search_results, program):\n",
        "\n",
        "                if likelihood > best_likelihood:\n",
        "                    best_match = (title, link, snippet, likelihood)\n",
        "                    best_likelihood = likelihood\n",
        "\n",
        "                if likelihood > 0.7:\n",
        "                    break  # Stop as soon as we find a strong match\n",
        "\n",
        "            if best_likelihood > 0.7 or not search_results:\n",
        "                break  # Stop searching if we found a strong match or no more results exist\n",
        "\n",
        "            start_index += 10  # Fetch next set of results\n",
        "\n",
        "            if start_index > 100:\n",
        "                break # Stop searching if we go too long\n",
        "\n",
        "        if not best_match:\n",
        "            results.append([year_taught, student_name, \"Not found\", \"\", \"\", \"\"])\n",
        "            continue  # Move to next student\n",
        "\n",
        "        title, link, snippet, likelihood = best_match\n",
        "\n",
        "        # Initial AI/ML Assessment Using LinkedIn Snippet\n",
        "        ai_ml_result = assess_ai_ml_from_snippet(title, snippet)\n",
        "        likelihood_ai_ml, summary = ai_ml_result.content.split(\"\\n\", 1)\n",
        "        likelihood_ai_ml = float(likelihood_ai_ml)\n",
        "\n",
        "        if likelihood_ai_ml < 0.6:\n",
        "            # Conduct General Web Search for Further Verification\n",
        "            refined_search_terms = suggest_refinement_terms(title, snippet)\n",
        "            general_search_results = search_general_web(student_name, \" \".join(refined_search_terms))\n",
        "\n",
        "            if general_search_results:\n",
        "                ai_ml_result = assess_ai_ml_likelihood(general_search_results)\n",
        "                likelihood_ai_ml, summary = ai_ml_result.content.split(\"\\n\", 1)\n",
        "                likelihood_ai_ml = float(likelihood_ai_ml)\n",
        "\n",
        "        results.append([year_taught, student_name, link, likelihood, likelihood_ai_ml, summary])\n",
        "\n",
        "    # Save results back to the specified spreadsheet\n",
        "    # Create a DataFrame with the correct column names\n",
        "    results_df = pd.DataFrame(results, columns=[\"Year\", \"Student Name\", \"LinkedIn URL\", \"Match Likelihood\", \"AI/ML Likelihood\", \"Reasoning\"])\n",
        "\n",
        "    results_df.to_excel(out_file_path, index=False)\n"
      ],
      "metadata": {
        "id": "fpoBl6hlCQkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we're inputting a spreadsheet with the names of the people I'd like to search for.\n",
        "\n",
        "Of course, this block won't work for someone who does not have these files stored on their google drive."
      ],
      "metadata": {
        "id": "Q8VXAKbO3Ycp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load spreadsheet\n",
        "#file = '/content/drive/MyDrive/Booth Students Taught short.xlsx'\n",
        "file = '/content/drive/MyDrive/Booth PhD Students Short.xlsx'\n",
        "\n",
        "#process_students(file, out_file_path='/content/drive/MyDrive/StudentSearchResults.xlsx')  # Process the whole file\n",
        "process_students(file, out_file_path='/content/drive/MyDrive/StudentSearchResults.xlsx', row_indices=range(2))  # Process the rows of the file specified in row_indices"
      ],
      "metadata": {
        "id": "JMX_da78EWku"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}